{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7731fa-1ab4-48cf-996c-a1a1fb6b2315",
   "metadata": {},
   "source": [
    "# Lec4. Adding Memory and Storage to LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3b0c75-2dd7-4662-b2ce-4e6b9208926c",
   "metadata": {},
   "source": [
    "Last week, we learned the basic elements of the framework LangChain. In this lecture, we are going to construct a vector store QA application from scratch.\n",
    "\n",
    ">Reference:\n",
    "> 1. [Ask A Book Questions](https://github.com/gkamradt/langchain-tutorials/blob/main/data_generation/Ask%20A%20Book%20Questions.ipynb)\n",
    "> 2. [Agent Vectorstore](https://python.langchain.com/docs/modules/agents/how_to/agent_vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a649ab-bb72-4894-b526-c97a7aa1fd81",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34411a5b-ad45-4bf0-bf8e-91f71b256337",
   "metadata": {},
   "source": [
    "\n",
    "1. Get your Serpapi key, please sign up for a free account at the [Serpapi website](https://serpapi.com/); \n",
    "\n",
    "2. Get your Pinecone key, first regiter on the [Pinecone website](https://www.pinecone.io/), **Create API Key**.\n",
    "\n",
    "3. Store your keys in a file named **.env** and place it in the current path or in a location that can be accessed.\n",
    "    ```\n",
    "    OPENAI_API_KEY='YOUR-OPENAI-API-KEY'\n",
    "    OPENAI_BASE_URL='OPENAI_API_URL'\n",
    "    SERPAPI_API_KEY=\"YOUR-SERPAPI-API-KEY\"\n",
    "    PINECONE_API_KEY=\"YOUR-PINECONE-API-KEY\" ## Optional\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defc9a3a-9f4c-49ff-8546-5799ff78b457",
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Install the requirements.  (Already installed in your image.)\n",
    "#%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb49c80a-4c12-4829-bef9-91076a4af689",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "CHAT_MODEL=\"deepseek-v3\"\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.environ.get(\"INFINI_API_KEY\")  # langchain use this environment variable to find the OpenAI API key\n",
    "os.environ[\"OPENAI_BASE_URL\"]=os.environ.get(\"INFINI_BASE_URL\") # will be used to pass the OpenAI base URL to langchain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5009a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility function\n",
    "\n",
    "from pprint import pprint\n",
    "def print_with_type(res):\n",
    "    pprint(f\"%s:\" % type(res))\n",
    "    pprint(res)\n",
    "\n",
    "    #pprint(f\"%s : %s\" % (type(res), res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f419461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a langchain chat model\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=CHAT_MODEL,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6d6985-1b36-4142-90b1-ad6386eb4335",
   "metadata": {},
   "source": [
    "## 1. Adding memory to remember the context\n",
    "Ref:\n",
    "https://python.langchain.com/v0.2/docs/how_to/chatbots_memory/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6809691-6aa5-4062-8d9e-1c620f9c6d2f",
   "metadata": {},
   "source": [
    "### 1.1 Use ChatMessageHistory to store the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bf03a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Translate this sentence from English to French: I love programming.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"J'adore la programmation.\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here is an information of using ChatMessageHistory to store the context\n",
    "# chatmessagehistory is nothing but a list of messages\n",
    "# you can add user message and ai message to the list\n",
    "# you can also get the history as a list of messages (this is useful if you are using this with a langchain chat model)\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\n",
    "    \"Translate this sentence from English to French: I love programming.\"\n",
    ")\n",
    "\n",
    "chat_history.add_ai_message(\"J'adore la programmation.\")\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "235a38b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The translation of \"enjoy your meal\" in French is:  \n",
      "\n",
      "**\"Bon appétit !\"**  \n",
      "\n",
      "This is the most common and natural way to wish someone a good meal in French.  \n",
      "\n",
      "Other variations (depending on context):  \n",
      "- **\"Régalez-vous !\"** (More informal, like \"Enjoy!\")  \n",
      "- **\"Savourez bien votre repas !\"** (More formal/literal)  \n",
      "\n",
      "But **\"Bon appétit\"** is the standard phrase. 😊\n"
     ]
    }
   ],
   "source": [
    "# adding the chat history to a prompt\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),   # add a placeholder for the chat history\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "# add a new question to the chat history\n",
    "next_question = \"translate 'enjoy your meal'\"  # note that here we do not tell LLM about the language\n",
    "chat_history.add_user_message(next_question)\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"history\": chat_history.messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49c15064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, the chat history is only a list of messages\n",
    "# you need to manually maintain it by adding user message and ai message to the list\n",
    "# nothing interesting :)\n",
    "\n",
    "chat_history.add_ai_message(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d33bc929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked me to translate \"enjoy your meal.\"\n"
     ]
    }
   ],
   "source": [
    "# let's continue with the history\n",
    "input2 = \"What did I just ask you?\"\n",
    "chat_history.add_user_message(input2)\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"history\": chat_history.messages,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694fa8be",
   "metadata": {},
   "source": [
    "Nothing interesting, let's see how to manage the history automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d7eafa",
   "metadata": {},
   "source": [
    "### 1.2 Managing Conversation Memory automatically in a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e349aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bcda99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"You are a chatbot having a conversation with a human.\n",
    "            Your name is Tom Riddle.\n",
    "            You need to tell your name to that human if he doesn't know.\"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1151bc8f",
   "metadata": {},
   "source": [
    "We'll pass the latest input to the conversation here and let the RunnableWithMessageHistory class wrap our chain and do the work of appending that input variable to the chat history.\n",
    "\n",
    "Next, let's declare our wrapped chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76ea87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "\n",
    "# Here we use a global variable to store the chat message history.\n",
    "# This will make it easier to inspect it to see the underlying results.\n",
    "store = {}\n",
    "\n",
    "def get_session_history(\n",
    "    user_id: str\n",
    ") -> BaseChatMessageHistory:\n",
    "    if (user_id) not in store:\n",
    "        store[(user_id)] = ChatMessageHistory()\n",
    "    return store[(user_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "990d01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    history_factory_config=[  # parameter for the get_session_history function\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db79f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, Harry Potter. It seems you've already made some notable connections. Ron Weasley and Hermione Granger—interesting choices. Friendship can be a powerful tool, but remember, not all alliances are as they seem. Keep your wits about you. I am Tom Riddle, by the way.\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_message_history.invoke(\n",
    "    {\"input\": \"Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.\",\n",
    "     \"history\": chat_history.messages},  # Pass history here\n",
    "    config={\"configurable\": {\"user_id\": \"123\"}},  # argument for the get_session_history function\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e12e8428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hello, Harry Potter. It seems you've already made some notable connections. Ron Weasley and Hermione Granger—interesting choices. Friendship can be a powerful tool, but remember, not all alliances are as they seem. Keep your wits about you. I am Tom Riddle, by the way.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 111, 'total_tokens': 174, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'da77317dec8e49b982e97ac2d5375cfd', 'finish_reason': 'stop', 'logprobs': None}, id='run-899bb917-335b-45b0-a4d6-f9fee23df70b-0', usage_metadata={'input_tokens': 111, 'output_tokens': 63, 'total_tokens': 174, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of messages in the memory \n",
    "store[\"123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b0cf684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don’t have access to personal information, so I wouldn’t know the names of your best friends. Perhaps you could tell me about them?\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_message_history.invoke(\n",
    "    {\"input\": \"What are my best friends' names?\",\n",
    "     \"history\": chat_history.messages},  # Pass history here\n",
    "    config={\"configurable\": {\"user_id\": \"123\"}},  # argument for the get_session_history function\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ace5b2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi there, this is Harry Potter, I just got two good friends at Hogwarts, Ron Weasley and Hermione Granger.', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Hello, Harry Potter. It seems you've already made some notable connections. Ron Weasley and Hermione Granger—interesting choices. Friendship can be a powerful tool, but remember, not all alliances are as they seem. Keep your wits about you. I am Tom Riddle, by the way.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 63, 'prompt_tokens': 111, 'total_tokens': 174, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'da77317dec8e49b982e97ac2d5375cfd', 'finish_reason': 'stop', 'logprobs': None}, id='run-899bb917-335b-45b0-a4d6-f9fee23df70b-0', usage_metadata={'input_tokens': 111, 'output_tokens': 63, 'total_tokens': 174, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content=\"What are my best friends' names?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I don’t have access to personal information, so I wouldn’t know the names of your best friends. Perhaps you could tell me about them?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 92, 'total_tokens': 124, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'e9b115317464464d8d9996183420a047', 'finish_reason': 'stop', 'logprobs': None}, id='run-154e985f-82e4-41a2-9be8-9b1912dba3c4-0', usage_metadata={'input_tokens': 92, 'output_tokens': 32, 'total_tokens': 124, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get a list of messages in the memory \n",
    "store[\"123\"].messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5184cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a human interacting with me, Tom Riddle. Let me know how I can assist you further!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = chain_with_message_history.invoke(\n",
    "    {\"input\": \"Who am I?\",\n",
    "     \"history\": chat_history.messages},  # Pass history here\n",
    "    config={\"configurable\": {\"user_id\": \"000\"}},  # argument for the get_session_history function\n",
    ")\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91731a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Who am I?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='You are a human interacting with me, Tom Riddle. Let me know how I can assist you further!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 88, 'total_tokens': 111, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': '7ad4893e9aa64aae86be657b764b0b22', 'finish_reason': 'stop', 'logprobs': None}, id='run-7cf2653e-a1f6-4494-a00a-00f43c2026c7-0', usage_metadata={'input_tokens': 88, 'output_tokens': 23, 'total_tokens': 111, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store[\"000\"].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532fab2",
   "metadata": {},
   "source": [
    "### Trimming messages\n",
    "LLMs and chat models have limited context windows, and even if you're not directly hitting limits, you may want to limit the amount of distraction the model has to deal with. One solution is trim the historic messages before passing them to the model. Let's use an example history with some preloaded messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed2ab5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hey there! I'm Nemo.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's create a new history, nemo\n",
    "store[\"nemo\"] = ChatMessageHistory()\n",
    "\n",
    "store[\"nemo\"] .add_user_message(\"Hey there! I'm Nemo.\")\n",
    "store[\"nemo\"] .add_ai_message(\"Hello!\")\n",
    "store[\"nemo\"] .add_user_message(\"How are you today?\")\n",
    "store[\"nemo\"] .add_ai_message(\"Fine thanks!\")\n",
    "\n",
    "store[\"nemo\"] .messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17f228bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    history_factory_config=[  # parameter for the get_session_history function\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],    \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6dae4703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Tom Riddle. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = chain_with_message_history.invoke(\n",
    "    {\"input\": \"What's my name?\",\n",
    "     \"history\": chat_history.messages},  # Pass history here\n",
    "    config={\"configurable\": {\"user_id\": \"nemo\"}},  # argument for the get_session_history function\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ec9958",
   "metadata": {},
   "source": [
    "We can see the chain remembers the preloaded name.\n",
    "\n",
    "But let's say we have a very small context window, and we want to trim the number of messages passed to the chain to only the 2 most recent ones. We can use the built in trim_messages util to trim messages based on their token count before they reach our prompt. In this case we'll count each message as 1 \"token\" and keep only the last two messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "081c5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.messages import trim_messages\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "trimmer = trim_messages(strategy=\"last\", max_tokens=1, token_counter=len)\n",
    "\n",
    "chain_with_trimming = (\n",
    "    RunnablePassthrough.assign(chat_history=itemgetter(\"chat_history\") | trimmer)\n",
    "    | prompt\n",
    "    | chat\n",
    ")\n",
    "\n",
    "chain_with_trimmed_history = RunnableWithMessageHistory(\n",
    "    chain_with_trimming,\n",
    "    get_session_history=get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    history_factory_config=[  # parameter for the get_session_history function\n",
    "        ConfigurableFieldSpec(\n",
    "            id=\"user_id\",\n",
    "            annotation=str,\n",
    "            name=\"User ID\",\n",
    "            description=\"Unique identifier for the user.\",\n",
    "            default=\"\",\n",
    "            is_shared=True,\n",
    "        ),\n",
    "    ],    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c66f842",
   "metadata": {},
   "source": [
    "Let's call this new chain and check the messages afterwards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1190732c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beijing is the capital city of China, located in the northern part of the country. It is a major cultural, historical, and political center. However, it seems you didn’t actually ask this question—you asked me what you had just asked me! Let me know if you'd like more information about Beijing or anything else.\n"
     ]
    }
   ],
   "source": [
    "# you ask something irrelavant to the chat history\n",
    "# and see if the history is trimmed\n",
    "response = chain_with_message_history.invoke(\n",
    "    {\"input\": \"where is beijing?\",\n",
    "     \"history\": chat_history.messages},  # Pass history here\n",
    "    config={\"configurable\": {\"user_id\": \"nemo\"}},  # argument for the get_session_history function\n",
    ")\n",
    "\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b98eaa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hey there! I'm Nemo.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Tom Riddle. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 89, 'total_tokens': 104, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'c8caa83b6bd1478daf2fa0b9e98d1c09', 'finish_reason': 'stop', 'logprobs': None}, id='run-28f6fbfe-6731-44ee-bf70-0b7d3979a3de-0', usage_metadata={'input_tokens': 89, 'output_tokens': 15, 'total_tokens': 104, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content='where is beijing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Beijing is the capital city of China, located in the northern part of the country. It is a major cultural, historical, and political center. However, it seems you didn’t actually ask this question—you asked me what you had just asked me! Let me know if you'd like more information about Beijing or anything else.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 89, 'total_tokens': 157, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'a069da9511064c80a1223180222a34da', 'finish_reason': 'stop', 'logprobs': None}, id='run-a394a806-e02a-4ef8-b266-6f9331f563d0-0', usage_metadata={'input_tokens': 89, 'output_tokens': 68, 'total_tokens': 157, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in fact, the history is still there, just not passed to the model\n",
    "store[\"nemo\"].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55777cd7",
   "metadata": {},
   "source": [
    "The next time the chain is called, trim_messages will be called again, and only the two most recent messages will be passed to the model. In this case, this means that the model will forget the name we gave it the next time we invoke it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "100efdb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Tom Riddle. How may I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# see if the history is trimmed (forgot the name nemo)\n",
    "response = chain_with_message_history.invoke(\n",
    "    {\"input\": \"What is my name?\",\n",
    "     \"history\": chat_history.messages},  # Pass history here\n",
    "    config={\"configurable\": {\"user_id\": \"nemo\"}},  # argument for the get_session_history function\n",
    ")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65050b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hey there! I'm Nemo.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Tom Riddle. How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 89, 'total_tokens': 104, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'c8caa83b6bd1478daf2fa0b9e98d1c09', 'finish_reason': 'stop', 'logprobs': None}, id='run-28f6fbfe-6731-44ee-bf70-0b7d3979a3de-0', usage_metadata={'input_tokens': 89, 'output_tokens': 15, 'total_tokens': 104, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content='where is beijing?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"Beijing is the capital city of China, located in the northern part of the country. It is a major cultural, historical, and political center. However, it seems you didn’t actually ask this question—you asked me what you had just asked me! Let me know if you'd like more information about Beijing or anything else.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 89, 'total_tokens': 157, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'a069da9511064c80a1223180222a34da', 'finish_reason': 'stop', 'logprobs': None}, id='run-a394a806-e02a-4ef8-b266-6f9331f563d0-0', usage_metadata={'input_tokens': 89, 'output_tokens': 68, 'total_tokens': 157, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Your name is Tom Riddle. How may I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 89, 'total_tokens': 104, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': '86672ab6b844442a8103656d8cd070a6', 'finish_reason': 'stop', 'logprobs': None}, id='run-d6dbd605-459a-4987-b8c4-54ef4831d128-0', usage_metadata={'input_tokens': 89, 'output_tokens': 15, 'total_tokens': 104, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# of course, the history is actually still there (just not seen by the model)\n",
    "store[\"nemo\"].messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44769a3",
   "metadata": {},
   "source": [
    "Haha, the model forgot the name we gave it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939788f5",
   "metadata": {},
   "source": [
    "### Summary memory\n",
    "We can use this same pattern in other ways too. For example, we could use an additional LLM call to generate a summary of the conversation before calling our chain. Let's recreate our chat history and chatbot chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8509600d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Hey there! I'm Nemo.\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hello!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='How are you today?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Fine thanks!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history = ChatMessageHistory()\n",
    "\n",
    "chat_history.add_user_message(\"Hey there! I'm Nemo.\")\n",
    "chat_history.add_ai_message(\"Hello!\")\n",
    "chat_history.add_user_message(\"How are you today?\")\n",
    "chat_history.add_ai_message(\"Fine thanks!\")\n",
    "\n",
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af9f28",
   "metadata": {},
   "source": [
    "We'll slightly modify the prompt to make the LLM aware that will receive a condensed summary instead of a chat history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f93937e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability. The provided chat history includes facts about the user you are speaking with.\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain_with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    lambda session_id: chat_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9afb7c",
   "metadata": {},
   "source": [
    "And now, let's create a function that will distill previous interactions into a summary. We can add this one to the front of the chain too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "210abc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_messages(chain_input):\n",
    "    stored_messages = chat_history.messages\n",
    "    if len(stored_messages) == 0:\n",
    "        return False\n",
    "    summarization_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"placeholder\", \"{chat_history}\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Distill the above chat messages into a single summary message. Include as many specific details as you can.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "    summarization_chain = summarization_prompt | chat\n",
    "\n",
    "    summary_message = summarization_chain.invoke({\"chat_history\": stored_messages})\n",
    "\n",
    "    chat_history.clear()\n",
    "\n",
    "    chat_history.add_message(summary_message)\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "chain_with_summarization = (\n",
    "    RunnablePassthrough.assign(messages_summarized=summarize_messages)\n",
    "    | chain_with_message_history\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e4c79",
   "metadata": {},
   "source": [
    "Let's see if it remembers the name we gave it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d456b1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You mentioned that your name is Nemo.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_with_summarization.invoke(\n",
    "    {\"input\": \"What did I say my name was?\"},\n",
    "    {\"configurable\": {\"session_id\": \"unused\"}},\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b36fa9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='Nemo initiated the conversation with a greeting, and I responded with a friendly \"Hello!\" When Nemo asked how I was today, I replied, \"Fine thanks!\" This brief exchange captures a polite and casual interaction between Nemo and me.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 48, 'total_tokens': 98, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': '0a7b7dcc0896425f826fb8573d151fca', 'finish_reason': 'stop', 'logprobs': None}, id='run-b560cbb7-c638-4e2a-bbef-2afded30f696-0', usage_metadata={'input_tokens': 48, 'output_tokens': 50, 'total_tokens': 98, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " HumanMessage(content='What did I say my name was?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='You mentioned that your name is Nemo.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 92, 'total_tokens': 102, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'deepseek-v3', 'system_fingerprint': None, 'id': 'f89a947017644dc48586644743ea9026', 'finish_reason': 'stop', 'logprobs': None}, id='run-2e918bc3-55b1-422f-816b-39e88110edb1-0', usage_metadata={'input_tokens': 92, 'output_tokens': 10, 'total_tokens': 102, 'input_token_details': {}, 'output_token_details': {}})]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ab1e54-6c47-43ea-9750-af8840c1494d",
   "metadata": {},
   "source": [
    "### 1.3 Adding Memory to Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8bf04-34d1-4a86-82f8-de39be61b836",
   "metadata": {},
   "source": [
    "In this section, we will first ask the agent a question, and then without mention the context information ourselves ask another related question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edba9d7b-5baa-4769-9c2a-d11164941fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, Tool, ZeroShotAgent\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9088da52-e54b-468e-a158-9220360ea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = SerpAPIWrapper()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ee6d6dd-39eb-425f-bdda-8d5dc07e3038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124176/4123490672.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\")\n"
     ]
    }
   ],
   "source": [
    "prompt = ZeroShotAgent.create_prompt(\n",
    "    tools,\n",
    "    prefix=\"\"\"Have a conversation with a human, answering the following questions as best you can.  You have access to the following tools:\"\"\",\n",
    "    suffix=\"\"\"Begin!  \n",
    "{chat_history}\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\",\n",
    "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"],\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0a5b87b-2c41-4b4a-b14a-cb30838c561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_124176/2362579863.py:2: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=chat, prompt=prompt)\n",
      "/tmp/ipykernel_124176/2362579863.py:3: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(model=CHAT_MODEL, temperature=0)\n",
    "llm_chain = LLMChain(llm=chat, prompt=prompt)\n",
    "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
    "agent_chain = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=memory, handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed18da6e-6754-4b8b-8951-4bf916e3d80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: To answer the question about the population of China in 2024, I need to find the most recent and reliable data. I will use the Search tool to look for this information.\n",
      "\n",
      "Action: Search  \n",
      "Action Input: \"population of China in 2024\"  \n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3maround 1.408 billion people\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThought: I have found the most recent and reliable data on the population of China in 2024.  \n",
      "Final Answer: The population of China in 2024 is approximately **1.408 billion people**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is the population of China in 2024?',\n",
       " 'chat_history': '',\n",
       " 'output': 'The population of China in 2024 is approximately **1.408 billion people**.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"What is the population of China in 2024?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd9a011d-c1cc-4c1c-bf43-7b505eb97c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chat_history': 'Human: What is the population of China in 2024?\\nAI: The population of China in 2024 is approximately **1.408 billion people**.'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dc74f05-4c59-4df3-800b-c2421e1d1263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: To compare the population of China and India in 2024, I need to find the population of India in 2024.  \n",
      "Action: Search  \n",
      "Action Input: \"Population of India in 2024\"  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'India Population (2025) - Worldometer', 'source': 'Worldometer', 'description': 'Population of India (2025 and historical)'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe search result provides information about India's population in 2025, but not specifically for 2024. However, based on current trends, India's population in 2024 is estimated to be slightly less than in 2025. According to recent data, India's population is projected to surpass China's in 2023, making it the most populous country in the world. Therefore, in 2024, India's population is likely to be **more** than China's population of approximately 1.408 billion.  \n",
      "Final Answer: In 2024, India's population is **more** than China's population.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Is it more or less than India?',\n",
       " 'chat_history': 'Human: What is the population of China in 2024?\\nAI: The population of China in 2024 is approximately **1.408 billion people**.',\n",
       " 'output': \"In 2024, India's population is **more** than China's population.\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"Is it more or less than India?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6539886a-230d-497e-bcf3-1f60fc6d607e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'chat_history': 'Human: What is the population of China in 2024?\\n'\n",
      "                 'AI: The population of China in 2024 is approximately **1.408 '\n",
      "                 'billion people**.\\n'\n",
      "                 'Human: Is it more or less than India?\\n'\n",
      "                 \"AI: India's population in 2024 is slightly more than \"\n",
      "                 \"China's, with approximately **1.428 billion people** \"\n",
      "                 \"compared to China's **1.408 billion people**.\"}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3ddfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: The user is asking for the population of China. I already provided this information earlier, but I will confirm it again.  \n",
      "Action: Search  \n",
      "Action Input: \"Population of China in 2024\"  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3maround 1.408 billion people\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: The population of China in 2024 is approximately **1.408 billion people**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the population in China?',\n",
       " 'chat_history': \"Human: What is the population of China in 2024?\\nAI: The population of China in 2024 is approximately **1.408 billion people**.\\nHuman: Is it more or less than India?\\nAI: India's population in 2024 is slightly more than China's, with approximately **1.428 billion people** compared to China's **1.408 billion people**.\",\n",
       " 'output': 'The population of China in 2024 is approximately **1.408 billion people**.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_chain.invoke(input=\"what is the population in China?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66de505a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'chat_history': 'Human: What is the population of China in 2024?\\n'\n",
      "                 'AI: The population of China in 2024 is approximately **1.408 '\n",
      "                 'billion people**.\\n'\n",
      "                 'Human: Is it more or less than India?\\n'\n",
      "                 \"AI: In 2024, India's population is **more** than China's \"\n",
      "                 'population.'}\n"
     ]
    }
   ],
   "source": [
    "print_with_type(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e01167-55ca-4ba1-836d-c00e648e4634",
   "metadata": {},
   "source": [
    "## 2. Long term memory with vector storage "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1c1f37-7026-4d59-bf87-70c94eed7afa",
   "metadata": {},
   "source": [
    "In this section, we are going to embed the famous Harry Potter book's first chapter into a vectorstore and try some similarity searches. We have some extra examples commented, you can uncomment and try them one-by-one. If you observe the results carefully, you may find the characteristics of similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc75f3-1fd9-4076-8a3f-d809b7dbf572",
   "metadata": {},
   "source": [
    "### 2.1 Loaders and Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d598ad",
   "metadata": {},
   "source": [
    "#### PDF Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cac64c7-69dc-4450-b2fa-ffd05740411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
    "\n",
    "data = PyPDFLoader(\"/ssdshare/share/lab4/harry-potter-chap-1.pdf\").load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43a7e514-29b0-44ad-afbd-529f67296153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 16 document(s) in your data\n",
      "There are 1835 characters in doc 0\n",
      "There are 2088 characters in doc 1\n",
      "There are 2081 characters in doc 2\n",
      "There are 1887 characters in doc 3\n",
      "There are 1879 characters in doc 4\n",
      "There are 1286 characters in doc 5\n",
      "There are 1851 characters in doc 6\n",
      "There are 1792 characters in doc 7\n",
      "There are 1535 characters in doc 8\n",
      "There are 1555 characters in doc 9\n",
      "There are 1622 characters in doc 10\n",
      "There are 1780 characters in doc 11\n",
      "There are 1528 characters in doc 12\n",
      "There are 1386 characters in doc 13\n",
      "There are 1870 characters in doc 14\n",
      "There are 1907 characters in doc 15\n"
     ]
    }
   ],
   "source": [
    "# Note: If you're using PyPDFLoader then it will split by page for you already\n",
    "\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "i = 0\n",
    "for d in data:\n",
    "    print (f'There are {len(d.page_content)} characters in doc {i}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2396be0",
   "metadata": {},
   "source": [
    "#### Text file loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c50f2983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "union = TextLoader(\"/ssdshare/share/lab4/state_of_the_union.txt\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3caf81f",
   "metadata": {},
   "source": [
    "#### Text Splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dce5a0a",
   "metadata": {},
   "source": [
    "From Langchain documents: \n",
    "\n",
    "RecursiveCharacterTextSplitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e29fd56-3275-4041-ad1c-63f71a9d0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can have some trials with different chunk_size and chunk_overlap.\n",
    "# This is optional, test out on your own data.\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=50)\n",
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e1a8d1fe-d24c-443d-bf68-43bdb0fc4bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 43 documents\n",
      "CHAPTER ONE \n",
      " \n",
      "THE BOY WHO LIVED \n",
      " \n",
      "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud t\n",
      "=========\n",
      "opinion there was no finer boy anywhere.  \n",
      " \n",
      "The Dursleys had everything they wanted, but they also \n",
      "=========\n",
      "Dudley mixing with a child like that. \n",
      " \n",
      "When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday\n",
      "=========\n",
      "work, and Mrs. Dursley gossiped away happily as she wrestled a \n",
      "screaming \n",
      "Dudley into his high chai\n",
      "=========\n",
      "Drive, but there wasn't a map in sight. What could he have been thinking  \n",
      "of? It must have been a t\n",
      "=========\n",
      "about. People in cloaks. Mr. Dursley couldn't bear people who dressed in  \n",
      "funny clothes -- the getu\n",
      "=========\n",
      "nerve of him! But then it struck Mr. Dursley that this was probably some  \n",
      "silly stunt -- these peop\n",
      "=========\n",
      "normal, owl-free morning. He yelled at five different people. He made  \n",
      "several important telephone \n",
      "=========\n",
      "Mr. Dursley stopped dead. Fear flooded him. He looked back at the  \n",
      "whisperers as if he wanted to sa\n",
      "=========\n",
      "of it, he wasn't even sure his nephew was called Harry. He'd never even  \n",
      "seen the boy. It might hav\n",
      "=========\n",
      "ground. On the contrary, his face split into a wide smile and he said in  \n",
      "a squeaky voice that made\n",
      "=========\n",
      "and it didn't improve his mood -- was the tabby cat he'd spotted that  \n",
      "morning. It was now sitting \n",
      "=========\n",
      "to pull himself together, he let himself into the house. He was still  \n",
      "determined not to mention an\n",
      "=========\n",
      "sunrise. Experts are unable to explain why the owls have suddenly  \n",
      "changed their sleeping pattern.\"\n",
      "=========\n",
      "Owls flying by daylight? Mysterious people in cloaks all over the place?  \n",
      "And a whisper, a whisper \n",
      "=========\n",
      "As he had expected, Mrs. Dursley looked shocked and angry. After all,  \n",
      "they normally pretended she \n",
      "=========\n",
      "\"What's his name again? Howard, isn't it?\"  \n",
      " \n",
      "\"Harry. Nasty, common name, if you ask me.\" \n",
      " \n",
      "\"Oh, y\n",
      "=========\n",
      "Potters? If it did... if it got out that they were related to a pair of \n",
      "-- well, he didn't think he\n",
      "=========\n",
      "on the wall outside was showing no sign of sleepiness. It was s itting as \n",
      "still as a statue, its ey\n",
      "=========\n",
      "a purple cloak that swept the ground, and high -heeled, buckled boots. \n",
      "His blue eyes were light, br\n",
      "=========\n",
      "street where everything from his name to his boots was unwelcome. He \n",
      "was \n",
      "busy rummaging in his clo\n",
      "=========\n",
      "were two tiny pinpricks in the distance, which were the eyes of the cat  \n",
      "watching him. If anyone lo\n",
      "=========\n",
      "wearing a cloak, an emerald one. Her black hair was drawn into a tight \n",
      "bun. She looked distinctly r\n",
      "=========\n",
      "Professor McGonagall. \n",
      " \n",
      "\"All day? When you could have been celebrating? I must have passed a  \n",
      "doze\n",
      "=========\n",
      "little to celebrate for eleven years.\" \n",
      " \n",
      "\"I know that,\" said Professor McGonagall irritably. \"But t\n",
      "=========\n",
      "\"No, thank you,\" said Professor McGonagall coldly, as though she didn't  \n",
      "think this was the moment \n",
      "=========\n",
      "the only one You-Know- oh, all right, Voldemort, was frightened of.\"  \n",
      " \n",
      "\"You flatter me,\" said Dumb\n",
      "=========\n",
      "Dumbledore with such a piercin g stare as she did now. It was plain that  \n",
      "whatever \"everyone\" was s\n",
      "=========\n",
      "They're saying he tried to kill the Potter's son, Harry. But -- he \n",
      "couldn't. He couldn't kill that \n",
      "=========\n",
      "golden watch from his pocket and examined it. It was a very odd watch.\n",
      "=========\n",
      "It had twelve hands but no numbers; instead, little planets were moving  \n",
      "around the edge. It must h\n",
      "=========\n",
      "him kicking his mother all the way up the street, screaming for sweets.  \n",
      "Harry Potter come and live\n",
      "=========\n",
      "half-moon glasses. \"It would be enough to turn any boy's head. Famous  \n",
      "before he can walk and talk!\n",
      "=========\n",
      "Professor McGonagall opened her mouth, changed her mind, swallowed, \n",
      "and \n",
      "then said, \"Yes -- yes, yo\n",
      "=========\n",
      "headlight; it swelled to a roar as they both looked up at the sky -- and \n",
      "a huge motorcycle fell out\n",
      "=========\n",
      "carefully off the motorcycle as he spoke. \"Young Sirius Black lent it to  \n",
      "me. I've got him, sir.\" \n",
      "\n",
      "=========\n",
      "above my left knee that is a perfect map of the London Underground. Well  \n",
      "-- give him here, Hagrid \n",
      "=========\n",
      "burying his face in it. \"But I c-c-can't stand it -- Lily an' James dead \n",
      "-- an' poor little Harry o\n",
      "=========\n",
      "Dumbledore's eyes seemed to have gone out.  \n",
      " \n",
      "\"Well,\" said Dumbledore finally, \"that's that. We've \n",
      "=========\n",
      "twelve balls of light sped back to their street lamps so that Privet  \n",
      "Drive glowed suddenly orange \n",
      "=========\n",
      "A breeze ruffled the neat hedges of Privet Drive, which lay silent and  \n",
      "tidy under the inky sky, th\n",
      "=========\n",
      "who lived!\" \n",
      " \n",
      " \n",
      "CHAPTER TWO \n",
      " \n",
      "THE VANISHING GLASS \n",
      " \n",
      "Nearly ten years had passed since the Dursley\n",
      "=========\n",
      "blond boy riding his first bicycle, on a carousel at the fair, playing a  \n",
      "computer game with his fa\n",
      "=========\n"
     ]
    }
   ],
   "source": [
    "print (f'Now you have {len(texts)} documents')\n",
    "\n",
    "for t in texts:\n",
    "    print(t.page_content[:100])\n",
    "    print(\"=========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f515d70a",
   "metadata": {},
   "source": [
    "There are different kinds of splitters.  \n",
    "\n",
    "https://chunkviz.up.railway.app/ \n",
    "\n",
    "provides a great tool to see the splitter differences with different chunk_size and chunk_overlap settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a49db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/lab4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnstructuredPDFLoader loaded 1 documents in 848.46 seconds\n",
      "First document sample: eo great bi\n",
      "\n",
      "room is\n",
      "\n",
      "HARRY POTTER\n",
      "\n",
      "AND THE SORCERER'S STONE\n",
      "\n",
      "ALSO BY J. K. ROWLING\n",
      "\n",
      "Harry Potter and the Sorcerer's Stone\n",
      "\n",
      "Year One at Hogwarts\n",
      "\n",
      "Harry Potter and the Chamber of Secrets Year Two at Ho...\n",
      "Does it handle images? False\n",
      "\n",
      "PyPDFLoader loaded 327 documents in 3.19 seconds\n",
      "First document sample: ...\n",
      "Does PyPDFLoader handle images? False\n",
      "\n",
      "PyMuPDFLoader loaded 327 documents in 0.62 seconds\n",
      "First document sample: ...\n",
      "Does PyMuPDFLoader handle images? False\n",
      "\n",
      "Comparison summary:\n",
      "- UnstructuredPDFLoader: 1 document, 453541 characters\n",
      "- PyPDFLoader: 327 documents (one per page)\n",
      "- PyMuPDFLoader: 327 documents (one per page)\n",
      "- UnstructuredPDFLoader: 453541 total characters extracted\n",
      "- PyPDFLoader: 462642 total characters extracted\n",
      "- PyMuPDFLoader: 457769 total characters extracted\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.document_loaders import UnstructuredPDFLoader, PyPDFLoader, PyMuPDFLoader\n",
    "import time\n",
    "import os\n",
    "\n",
    "#### Your TASK ####\n",
    "# Explore different PDF Loaders.  Which one works the best for this file /ssdshare/share/lab4/hp-book1.pdf ,\n",
    "# which contains the full book of Harry Potter Book 1, with all the illustratons.\n",
    "## Langchain provides many other options for loaders, read the documents to find out the differences\n",
    "# See page https://python.langchain.com/docs/modules/data_connection/document_loaders/pdf\n",
    "# File path\n",
    "hp_book_path = \"/ssdshare/share/lab4/hp-book1.pdf\"\n",
    "\n",
    "# Using UnstructuredPDFLoader to load the full Harry Potter book\n",
    "start_time = time.time()\n",
    "unstructured_data = UnstructuredPDFLoader(hp_book_path).load()\n",
    "print(f\"UnstructuredPDFLoader loaded {len(unstructured_data)} documents in {time.time() - start_time:.2f} seconds\")\n",
    "print(f\"First document sample: {unstructured_data[0].page_content[:200]}...\")\n",
    "# Check if UnstructuredPDFLoader handles images\n",
    "print(f\"Does it handle images? {'image' in str(unstructured_data[0].metadata).lower()}\")\n",
    "\n",
    "# Try PyPDFLoader\n",
    "start_time = time.time()\n",
    "pypdf_data = PyPDFLoader(hp_book_path).load()\n",
    "print(f\"\\nPyPDFLoader loaded {len(pypdf_data)} documents in {time.time() - start_time:.2f} seconds\")\n",
    "print(f\"First document sample: {pypdf_data[0].page_content[:200]}...\")\n",
    "print(f\"Does PyPDFLoader handle images? {'image' in str(pypdf_data[0].metadata).lower()}\")\n",
    "\n",
    "# Try PyMuPDFLoader\n",
    "start_time = time.time()\n",
    "pymupdf_data = PyMuPDFLoader(hp_book_path).load()\n",
    "print(f\"\\nPyMuPDFLoader loaded {len(pymupdf_data)} documents in {time.time() - start_time:.2f} seconds\")\n",
    "print(f\"First document sample: {pymupdf_data[0].page_content[:200]}...\")\n",
    "print(f\"Does PyMuPDFLoader handle images? {'image' in str(pymupdf_data[0].metadata).lower()}\")\n",
    "\n",
    "# Compare the loaders\n",
    "print(f\"\\nComparison summary:\")\n",
    "print(f\"- UnstructuredPDFLoader: {len(unstructured_data)} document, {len(unstructured_data[0].page_content)} characters\")\n",
    "print(f\"- PyPDFLoader: {len(pypdf_data)} documents (one per page)\")\n",
    "print(f\"- PyMuPDFLoader: {len(pymupdf_data)} documents (one per page)\")\n",
    "\n",
    "# Check file sizes and processing speed\n",
    "for i, (loader_name, data) in enumerate([\n",
    "    (\"UnstructuredPDFLoader\", unstructured_data), \n",
    "    (\"PyPDFLoader\", pypdf_data), \n",
    "    (\"PyMuPDFLoader\", pymupdf_data)\n",
    "]):\n",
    "    total_chars = sum(len(doc.page_content) for doc in data)\n",
    "    print(f\"- {loader_name}: {total_chars} total characters extracted\")\n",
    "\n",
    "# the code is generated by copilot (Claude 3.7 Sonnet Thinking), using prompt \"finish the task\". The output is not modified.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0c23cf-0d0a-4f79-9718-42d093fc4dd0",
   "metadata": {},
   "source": [
    "### 2.2 Create embeddings of your documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede1bbf6",
   "metadata": {},
   "source": [
    "Embedding is a model that turns a sentence into vectors, so that we can \"semantically search\" for related splits of a document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd92c90b-7f21-4c8b-9586-41abf20b409a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI embedding: slow and expensive, we do not use them here.  \n",
    "\n",
    "# from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "# openai_embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ee572a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.015141339041292667,\n",
       " 0.026687903329730034,\n",
       " -0.03798038884997368,\n",
       " 0.010680807754397392,\n",
       " 0.00907162856310606,\n",
       " -0.006441421341150999,\n",
       " 0.03607948496937752,\n",
       " 0.011330125853419304,\n",
       " 0.019950054585933685,\n",
       " 0.0050627971068024635,\n",
       " 0.012421732768416405,\n",
       " 0.011198380030691624,\n",
       " 0.006079120561480522,\n",
       " 0.011791235767304897,\n",
       " 0.023526009172201157,\n",
       " -0.004065294284373522,\n",
       " 0.026443233713507652,\n",
       " -0.024090632796287537,\n",
       " -0.006375548429787159,\n",
       " 0.007246010471135378,\n",
       " 0.011753593571484089,\n",
       " 0.012487605214118958,\n",
       " 0.0036135949194431305,\n",
       " -0.018096206709742546,\n",
       " -0.026894932612776756,\n",
       " -0.018773755058646202,\n",
       " -0.006093236152082682,\n",
       " 0.0021291037555783987,\n",
       " 8.028250158531591e-05,\n",
       " 0.0284947007894516,\n",
       " 0.001866788836196065,\n",
       " -0.019874772056937218,\n",
       " 0.03178834170103073,\n",
       " -0.015094286762177944,\n",
       " -0.027421915903687477,\n",
       " -0.019987696781754494,\n",
       " -0.0071566118858754635,\n",
       " -0.002731369575485587,\n",
       " -0.10502010583877563,\n",
       " -0.001976184779778123,\n",
       " 0.001282167504541576,\n",
       " -0.0002726076345425099,\n",
       " -0.018820807337760925,\n",
       " -0.03400919958949089,\n",
       " -0.013296900317072868,\n",
       " -0.00039200211176648736,\n",
       " -0.03715227171778679,\n",
       " 0.007166022434830666,\n",
       " -0.024467049166560173,\n",
       " -0.03607948496937752,\n",
       " 0.003046618076041341,\n",
       " 0.021060483530163765,\n",
       " 0.054580338299274445,\n",
       " -0.0004872824647463858,\n",
       " -0.03907199576497078,\n",
       " 0.006766079925000668,\n",
       " 0.014275581575930119,\n",
       " -0.018783165141940117,\n",
       " -0.06357668340206146,\n",
       " -0.03101668879389763,\n",
       " 0.011687721125781536,\n",
       " 0.026687903329730034,\n",
       " -0.015019004233181477,\n",
       " -0.05811865255236626,\n",
       " 0.007118970155715942,\n",
       " 0.08988817036151886,\n",
       " 0.003879438852891326,\n",
       " 0.010078541934490204,\n",
       " -0.018011512234807014,\n",
       " -0.01225234568119049,\n",
       " -0.021286332979798317,\n",
       " -0.014332044869661331,\n",
       " -0.02092873677611351,\n",
       " -0.01673169806599617,\n",
       " -0.07434218376874924,\n",
       " 0.03858265280723572,\n",
       " -0.0009275128832086921,\n",
       " -0.04931051284074783,\n",
       " -0.012026495300233364,\n",
       " 0.017108112573623657,\n",
       " 0.02341308444738388,\n",
       " -0.010577293112874031,\n",
       " 0.02235911786556244,\n",
       " 0.003474791534245014,\n",
       " 0.011433640494942665,\n",
       " 0.050364479422569275,\n",
       " -0.025784505531191826,\n",
       " 0.004827537108212709,\n",
       " -0.0031760111451148987,\n",
       " -0.018754934892058372,\n",
       " -0.0027784216217696667,\n",
       " 0.028833476826548576,\n",
       " 0.0367758572101593,\n",
       " -0.04215860739350319,\n",
       " -0.017625685781240463,\n",
       " 0.020006516948342323,\n",
       " -0.04008831828832626,\n",
       " 0.00641319015994668,\n",
       " 0.04795541614294052,\n",
       " 0.011650079861283302,\n",
       " 0.014877847395837307,\n",
       " -0.0036629994865506887,\n",
       " -0.01881139725446701,\n",
       " -0.007283652201294899,\n",
       " -0.021568644791841507,\n",
       " -0.05552138015627861,\n",
       " -0.0034559706691652536,\n",
       " 0.03899671137332916,\n",
       " -0.00012446728942450136,\n",
       " -0.023262517526745796,\n",
       " 0.037208735942840576,\n",
       " 0.014115605503320694,\n",
       " 0.01705165021121502,\n",
       " 0.00780122447758913,\n",
       " -0.004500525537878275,\n",
       " 0.006159109063446522,\n",
       " -0.020796991884708405,\n",
       " -0.009532738476991653,\n",
       " -0.004484057426452637,\n",
       " 0.01798328012228012,\n",
       " 0.008530531078577042,\n",
       " 0.06583518534898758,\n",
       " 0.04637446999549866,\n",
       " -0.0031666008289903402,\n",
       " 0.008850484155118465,\n",
       " 0.007904739119112492,\n",
       " -0.013325131498277187,\n",
       " 0.025483371689915657,\n",
       " 0.003935901448130608,\n",
       " 0.033651601523160934,\n",
       " 0.01608237996697426,\n",
       " 0.00850700493901968,\n",
       " -0.036135949194431305,\n",
       " -0.01803974248468876,\n",
       " -0.003879438852891326,\n",
       " -0.026085637509822845,\n",
       " 0.015621270053088665,\n",
       " 0.035251371562480927,\n",
       " -0.0156589113175869,\n",
       " -0.006328496150672436,\n",
       " 0.04249738156795502,\n",
       " 0.03039560280740261,\n",
       " -0.011527744121849537,\n",
       " -0.01886785961687565,\n",
       " 0.00669550197198987,\n",
       " -0.003413623897358775,\n",
       " 0.02787361480295658,\n",
       " -0.013325131498277187,\n",
       " -0.0037312249187380075,\n",
       " -0.03647472336888313,\n",
       " -0.029755694791674614,\n",
       " 0.011170148849487305,\n",
       " -0.00018482620362192392,\n",
       " 0.019743027165532112,\n",
       " 0.01786094531416893,\n",
       " -0.023864783346652985,\n",
       " -0.01144305057823658,\n",
       " 0.006926056928932667,\n",
       " -0.00355477980338037,\n",
       " 0.01383329275995493,\n",
       " 0.02454233169555664,\n",
       " -0.04325021430850029,\n",
       " -0.03041442483663559,\n",
       " 0.0012480547884479165,\n",
       " -0.014284992590546608,\n",
       " -0.0015291905729100108,\n",
       " 0.014181477949023247,\n",
       " 0.04325021430850029,\n",
       " -0.0015644795494154096,\n",
       " -0.0360042043030262,\n",
       " 0.007876507937908173,\n",
       " -0.04799305647611618,\n",
       " -0.019056066870689392,\n",
       " 0.009956207126379013,\n",
       " 0.015066055580973625,\n",
       " 0.008892831392586231,\n",
       " 0.015668321400880814,\n",
       " -0.00821528211236,\n",
       " -0.0020773466676473618,\n",
       " -0.02147454023361206,\n",
       " -0.03342575207352638,\n",
       " 0.007462449837476015,\n",
       " 0.0003061321913264692,\n",
       " -0.02424119971692562,\n",
       " -0.021098123863339424,\n",
       " 0.01422853022813797,\n",
       " 0.01282638031989336,\n",
       " 0.0019385430496186018,\n",
       " -0.004620508290827274,\n",
       " -0.007857686839997768,\n",
       " -0.024165915325284004,\n",
       " -0.007693004794418812,\n",
       " 0.017907997593283653,\n",
       " 0.01620471477508545,\n",
       " -0.006747259292751551,\n",
       " -0.028250031173229218,\n",
       " 0.00642730575054884,\n",
       " -0.02785479463636875,\n",
       " 0.028005361557006836,\n",
       " -0.013475697487592697,\n",
       " -0.0299062617123127,\n",
       " -0.0016585836419835687,\n",
       " 0.008412900380790234,\n",
       " -0.002637265482917428,\n",
       " 0.02008180133998394,\n",
       " -0.019743027165532112,\n",
       " -0.020025338977575302,\n",
       " -0.014586125500500202,\n",
       " 0.006314380560070276,\n",
       " -0.03064027428627014,\n",
       " -0.0313178226351738,\n",
       " 0.004898115061223507,\n",
       " -0.03293641284108162,\n",
       " 0.004992219153791666,\n",
       " -0.01947953552007675,\n",
       " 0.026725545525550842,\n",
       " 0.026179742068052292,\n",
       " 0.01660936139523983,\n",
       " 0.01437909621745348,\n",
       " 0.035627786070108414,\n",
       " 0.00974917784333229,\n",
       " -0.0029360458720475435,\n",
       " -0.019743027165532112,\n",
       " 0.03662528842687607,\n",
       " -0.007688299752771854,\n",
       " -0.017089292407035828,\n",
       " 0.023544829338788986,\n",
       " 0.03071555681526661,\n",
       " 0.005189837422221899,\n",
       " -0.047353148460388184,\n",
       " 0.02345072478055954,\n",
       " 0.015310726128518581,\n",
       " -0.00834702793508768,\n",
       " -0.007307178340852261,\n",
       " -0.017352784052491188,\n",
       " 0.009833871386945248,\n",
       " -0.02904050424695015,\n",
       " 0.023827141150832176,\n",
       " 0.030489707365632057,\n",
       " 0.06052771583199501,\n",
       " 0.030564989894628525,\n",
       " -0.024467049166560173,\n",
       " 0.02766658551990986,\n",
       " -0.011264252476394176,\n",
       " -0.018340876325964928,\n",
       " -0.014915489591658115,\n",
       " 0.006704912520945072,\n",
       " -0.02202034369111061,\n",
       " -0.0015150749823078513,\n",
       " 0.033331647515296936,\n",
       " -0.015969455242156982,\n",
       " -0.0324094295501709,\n",
       " -0.037547510117292404,\n",
       " -0.011113686487078667,\n",
       " -0.018604367971420288,\n",
       " 0.030470887199044228,\n",
       " 0.0005613893736153841,\n",
       " 0.010473779402673244,\n",
       " -0.013993269763886929,\n",
       " -0.0011092512868344784,\n",
       " -0.013485108502209187,\n",
       " 0.011113686487078667,\n",
       " -0.014284992590546608,\n",
       " 0.038130953907966614,\n",
       " -0.008267039433121681,\n",
       " 0.01313692331314087,\n",
       " -0.003230120986700058,\n",
       " -0.010294981300830841,\n",
       " 0.014416738413274288,\n",
       " 0.02124869078397751,\n",
       " 0.021945061162114143,\n",
       " -0.01978066749870777,\n",
       " -0.002249086508527398,\n",
       " 0.004382895305752754,\n",
       " 0.0022737886756658554,\n",
       " 0.03801802918314934,\n",
       " 0.022547326982021332,\n",
       " -0.023262517526745796,\n",
       " 0.04513229429721832,\n",
       " -0.0004805187345482409,\n",
       " -0.004175866488367319,\n",
       " 0.013588622212409973,\n",
       " 0.0212110485881567,\n",
       " 0.013061639852821827,\n",
       " -0.003477144055068493,\n",
       " 0.05017627030611038,\n",
       " -0.029360458254814148,\n",
       " -0.008591698482632637,\n",
       " -0.0074389236979186535,\n",
       " -0.05160665139555931,\n",
       " 0.060640640556812286,\n",
       " 0.00011476281360955909,\n",
       " -0.005683883558958769,\n",
       " 0.0017879765946418047,\n",
       " -0.008906946517527103,\n",
       " 0.03515726700425148,\n",
       " -0.020759349688887596,\n",
       " -0.1687849909067154,\n",
       " 0.03464910387992859,\n",
       " 0.022810818627476692,\n",
       " 0.0028913463465869427,\n",
       " 0.013917986303567886,\n",
       " 0.00768359424546361,\n",
       " -0.019686564803123474,\n",
       " -0.002398476470261812,\n",
       " 0.011781824752688408,\n",
       " -0.0024537628050893545,\n",
       " -0.010680807754397392,\n",
       " -0.017625685781240463,\n",
       " -0.03673821687698364,\n",
       " 0.024165915325284004,\n",
       " -0.001956187654286623,\n",
       " 0.03406566008925438,\n",
       " 0.001903254073113203,\n",
       " -0.0011492455378174782,\n",
       " 0.0074106925167143345,\n",
       " -0.03410330042243004,\n",
       " 0.00585327111184597,\n",
       " -0.0019173696637153625,\n",
       " 0.06602338701486588,\n",
       " -0.01173477340489626,\n",
       " -0.040577661246061325,\n",
       " 0.0051757218316197395,\n",
       " 0.007744762115180492,\n",
       " -0.04765428230166435,\n",
       " -0.026424413546919823,\n",
       " 0.0032818783074617386,\n",
       " -0.02766658551990986,\n",
       " 0.04908466339111328,\n",
       " -0.022754356265068054,\n",
       " -0.007415398024022579,\n",
       " -0.01594122312963009,\n",
       " -0.0030630864202976227,\n",
       " 0.034498538821935654,\n",
       " -0.0015197801403701305,\n",
       " -0.009504507295787334,\n",
       " 0.015131928957998753,\n",
       " -0.0003311285690870136,\n",
       " 0.002926635555922985,\n",
       " -0.018576135858893394,\n",
       " 0.05111731216311455,\n",
       " -0.00251493020914495,\n",
       " -0.06880886852741241,\n",
       " -0.047277867794036865,\n",
       " -0.002877230755984783,\n",
       " -0.009137501940131187,\n",
       " -0.014200299046933651,\n",
       " -0.0019632454495877028,\n",
       " 0.015103697776794434,\n",
       " -0.015414240770041943,\n",
       " -0.013889755122363567,\n",
       " -0.00817293580621481,\n",
       " 0.009382172487676144,\n",
       " 0.005199247971177101,\n",
       " 0.030602632090449333,\n",
       " 0.015489524230360985,\n",
       " -0.014567304402589798,\n",
       " -0.04803070053458214,\n",
       " -0.007584785111248493,\n",
       " 0.016581131145358086,\n",
       " 0.00766947865486145,\n",
       " -0.022547326982021332,\n",
       " -0.0011651255190372467,\n",
       " 0.01851026341319084,\n",
       " 0.023074308410286903,\n",
       " 0.03549604117870331,\n",
       " -0.015988275408744812,\n",
       " 0.023074308410286903,\n",
       " -0.012638172134757042,\n",
       " 0.01851026341319084,\n",
       " -0.0029031094163656235,\n",
       " 0.0029360458720475435,\n",
       " 0.020834634080529213,\n",
       " -0.04148105904459953,\n",
       " 0.00766947865486145,\n",
       " -0.002597271464765072,\n",
       " -0.0809294730424881,\n",
       " -0.018896089866757393,\n",
       " 0.007942380383610725,\n",
       " -0.027534840628504753,\n",
       " 0.02623620443046093,\n",
       " -0.014633177779614925,\n",
       " -0.005476854741573334,\n",
       " 0.018519673496484756,\n",
       " -0.019046656787395477,\n",
       " 0.04072822630405426,\n",
       " 0.614311158657074,\n",
       " 0.014275581575930119,\n",
       " -0.0004537578788585961,\n",
       " 0.0036065371241420507,\n",
       " -0.011603027582168579,\n",
       " -0.03216475993394852,\n",
       " 0.015574217773973942,\n",
       " 0.015818888321518898,\n",
       " -0.02426001988351345,\n",
       " -0.028043001890182495,\n",
       " -0.008036484941840172,\n",
       " 0.000101455909316428,\n",
       " 0.002329074777662754,\n",
       " -0.016477616503834724,\n",
       " -0.05409099906682968,\n",
       " 0.0524347685277462,\n",
       " -0.016957547515630722,\n",
       " -0.004060589242726564,\n",
       " -0.0002720194752328098,\n",
       " -0.033896274864673615,\n",
       " 0.006714323069900274,\n",
       " -0.018943142145872116,\n",
       " 0.006799016613513231,\n",
       " -0.011414819397032261,\n",
       " -0.002552571939304471,\n",
       " -0.01782330498099327,\n",
       " -0.004987513646483421,\n",
       " 0.021154586225748062,\n",
       " 0.026913754642009735,\n",
       " -0.003971190191805363,\n",
       " 0.0011515981750562787,\n",
       " -0.03372688591480255,\n",
       " 0.03301169350743294,\n",
       " 0.022716714069247246,\n",
       " -0.004218213260173798,\n",
       " -0.021305153146386147,\n",
       " -0.012995767407119274,\n",
       " -0.0017668032087385654,\n",
       " -0.02171921171247959,\n",
       " 0.03212711587548256,\n",
       " -0.013127513229846954,\n",
       " -0.030075648799538612,\n",
       " -0.006079120561480522,\n",
       " -0.027177244424819946,\n",
       " -0.021154586225748062,\n",
       " 0.0009651544969528913,\n",
       " -0.009015166200697422,\n",
       " 0.007340114563703537,\n",
       " -0.02369539625942707,\n",
       " 0.007194253616034985,\n",
       " -0.026650262996554375,\n",
       " 0.01949835568666458,\n",
       " -0.0284947007894516,\n",
       " 0.012882842682301998,\n",
       " -0.005439213011413813,\n",
       " 0.005834450013935566,\n",
       " -0.028908759355545044,\n",
       " 0.007095444016158581,\n",
       " 0.012130009941756725,\n",
       " -0.0005343344528228045,\n",
       " 0.0406905859708786,\n",
       " 0.02482464350759983,\n",
       " -0.029812157154083252,\n",
       " 0.012449963949620724,\n",
       " -0.010963119566440582,\n",
       " 0.01729632169008255,\n",
       " -0.002198505448177457,\n",
       " -0.0724601075053215,\n",
       " -0.010247929021716118,\n",
       " 0.013165154494345188,\n",
       " 0.034479718655347824,\n",
       " 0.007805929519236088,\n",
       " -0.005321583244949579,\n",
       " 0.00855876225978136,\n",
       " 0.009843282401561737,\n",
       " 0.017324551939964294,\n",
       " -0.003470086259767413,\n",
       " -0.002382008358836174,\n",
       " 0.010266750119626522,\n",
       " 0.008935177698731422,\n",
       " -0.005025155376642942,\n",
       " -0.04490644484758377,\n",
       " 0.012967536225914955,\n",
       " -0.018801985308527946,\n",
       " 0.006737848743796349,\n",
       " -0.0063614328391849995,\n",
       " -0.028965221717953682,\n",
       " -0.0002839295193552971,\n",
       " 0.019347788766026497,\n",
       " 0.014397917315363884,\n",
       " 0.014849616214632988,\n",
       " -0.01340041495859623,\n",
       " -0.024410586804151535,\n",
       " 0.013287489302456379,\n",
       " -0.0007969435537233949,\n",
       " -0.009702125564217567,\n",
       " 0.031186077743768692,\n",
       " -0.035815995186567307,\n",
       " -0.01775743067264557,\n",
       " 0.0094668660312891,\n",
       " 0.011207790113985538,\n",
       " -0.02431648224592209,\n",
       " 0.0058767967857420444,\n",
       " -0.03235296532511711,\n",
       " 0.042535021901130676,\n",
       " 0.022265015169978142,\n",
       " -0.011922981590032578,\n",
       " -0.018754934892058372,\n",
       " -0.03575953468680382,\n",
       " 0.020458217710256577,\n",
       " 0.00564153678715229,\n",
       " -0.002764306031167507,\n",
       " 0.0010057368781417608,\n",
       " -0.000768712314311415,\n",
       " -0.00886930525302887,\n",
       " 0.014520252123475075,\n",
       " 0.033877450972795486,\n",
       " 0.0019173696637153625,\n",
       " 0.00045346381375566125,\n",
       " 0.00941510871052742,\n",
       " -0.056763552129268646,\n",
       " -0.028080644086003304,\n",
       " 0.011076045222580433,\n",
       " 0.017550403252243996,\n",
       " -0.0212110485881567,\n",
       " -0.028043001890182495,\n",
       " -0.0013574507320299745,\n",
       " 0.024429406970739365,\n",
       " -0.05488147214055061,\n",
       " 0.025313984602689743,\n",
       " -0.012224114499986172,\n",
       " -0.04110464081168175,\n",
       " -0.03775453940033913,\n",
       " 0.005340403877198696,\n",
       " 0.05864563584327698,\n",
       " -0.009824461303651333,\n",
       " 0.06756670027971268,\n",
       " 0.020985199138522148,\n",
       " -0.039222560822963715,\n",
       " 0.019724205136299133,\n",
       " -0.038695577532052994,\n",
       " 0.0005111025529913604,\n",
       " -0.024184737354516983,\n",
       " -0.007867096923291683,\n",
       " -0.007768288254737854,\n",
       " 0.04603569209575653,\n",
       " -0.021907418966293335,\n",
       " 0.0637272521853447,\n",
       " 0.0005678590387105942,\n",
       " -0.003543016966432333,\n",
       " 0.026311488822102547,\n",
       " 0.004232328850775957,\n",
       " 0.026631440967321396,\n",
       " -0.039147280156612396,\n",
       " -0.015009593218564987,\n",
       " -0.03342575207352638,\n",
       " -0.010464368388056755,\n",
       " -0.011593617498874664,\n",
       " -0.012026495300233364,\n",
       " -0.009339825250208378,\n",
       " 0.027271348983049393,\n",
       " 0.02089109644293785,\n",
       " -0.008130588568747044,\n",
       " 0.07577256858348846,\n",
       " -0.005410981830209494,\n",
       " 0.01913134939968586,\n",
       " -0.008492888882756233,\n",
       " 0.036154769361019135,\n",
       " 0.015113107860088348,\n",
       " -0.021850956603884697,\n",
       " -0.02986862137913704,\n",
       " -0.013052229769527912,\n",
       " 0.010972530581057072,\n",
       " 0.04121756553649902,\n",
       " -0.006596692837774754,\n",
       " 0.04012595862150192,\n",
       " 0.012638172134757042,\n",
       " 0.02117340825498104,\n",
       " -0.028871117159724236,\n",
       " -0.037547510117292404,\n",
       " 0.015197801403701305,\n",
       " -0.003286583349108696,\n",
       " -0.029680412262678146,\n",
       " -0.019423073157668114,\n",
       " -0.006836657878011465,\n",
       " 0.03355749696493149,\n",
       " 0.0021255749743431807,\n",
       " 0.00886930525302887,\n",
       " 0.020307650789618492,\n",
       " -0.02508813515305519,\n",
       " -0.016251767054200172,\n",
       " 0.0654587671160698,\n",
       " 0.005481559783220291,\n",
       " -0.019244274124503136,\n",
       " 0.010680807754397392,\n",
       " 0.019441893324255943,\n",
       " 0.018322056159377098,\n",
       " 0.04106700047850609,\n",
       " 0.008732854388654232,\n",
       " -0.051456086337566376,\n",
       " -0.03903435170650482,\n",
       " -0.02510695718228817,\n",
       " -0.01620471477508545,\n",
       " 0.0023278985172510147,\n",
       " 0.004992219153791666,\n",
       " -0.01818089932203293,\n",
       " -0.015555396676063538,\n",
       " 0.007104854565113783,\n",
       " -0.007848276756703854,\n",
       " 0.03216475993394852,\n",
       " 0.013165154494345188,\n",
       " -0.008182345889508724,\n",
       " 0.011358357034623623,\n",
       " -0.002698433119803667,\n",
       " 0.00254786666482687,\n",
       " -0.014002680778503418,\n",
       " 0.03069673664867878,\n",
       " 0.01701400987803936,\n",
       " 0.015978865325450897,\n",
       " -0.010981940664350986,\n",
       " -0.020778171718120575,\n",
       " 0.020778171718120575,\n",
       " 0.02563393861055374,\n",
       " -0.025201059877872467,\n",
       " 0.017729200422763824,\n",
       " 0.018331466242671013,\n",
       " -0.025050494819879532,\n",
       " -0.011236021295189857,\n",
       " -0.04577220231294632,\n",
       " 0.018905499950051308,\n",
       " -0.006403779610991478,\n",
       " -0.041405774652957916,\n",
       " 0.006159109063446522,\n",
       " -0.010530241765081882,\n",
       " -0.0029148724861443043,\n",
       " -0.0033948030322790146,\n",
       " 0.018896089866757393,\n",
       " 0.020571142435073853,\n",
       " 0.0037947450764477253,\n",
       " -0.019225453957915306,\n",
       " -0.006460241973400116,\n",
       " -0.005194542929530144,\n",
       " -0.0013021646300330758,\n",
       " 0.041706908494234085,\n",
       " -0.017729200422763824,\n",
       " 0.03190126642584801,\n",
       " -0.015931813046336174,\n",
       " -0.004439357668161392,\n",
       " 0.001015147310681641,\n",
       " 0.06380253285169601,\n",
       " -0.01326866913586855,\n",
       " 0.008375259116292,\n",
       " 0.007293062750250101,\n",
       " -0.010229108855128288,\n",
       " -0.008643455803394318,\n",
       " 0.0377357192337513,\n",
       " -0.003712404053658247,\n",
       " 0.0276289451867342,\n",
       " -0.0395989790558815,\n",
       " 0.016439974308013916,\n",
       " 0.010803143493831158,\n",
       " 0.016759928315877914,\n",
       " 0.005100438836961985,\n",
       " -0.015376599505543709,\n",
       " 0.015818888321518898,\n",
       " -0.0226226095110178,\n",
       " 0.029981546103954315,\n",
       " 0.017362194135785103,\n",
       " 0.004945166874676943,\n",
       " -0.03656882792711258,\n",
       " -0.03735930100083351,\n",
       " -0.01228057686239481,\n",
       " -0.026687903329730034,\n",
       " -0.03210829570889473,\n",
       " 0.041970398277044296,\n",
       " 0.004053531214594841,\n",
       " 0.024109452962875366,\n",
       " 0.05921025946736336,\n",
       " 0.002827826188877225,\n",
       " 0.003503022715449333,\n",
       " -0.00262079737149179,\n",
       " 0.01594122312963009,\n",
       " -0.006766079925000668,\n",
       " 0.009542149491608143,\n",
       " -0.00524159474298358,\n",
       " -0.026857292279601097,\n",
       " -0.001257465104572475,\n",
       " 0.003168953349813819,\n",
       " -0.01032321248203516,\n",
       " 0.005961490795016289,\n",
       " 0.04739079251885414,\n",
       " -0.0018091500969603658,\n",
       " -0.016054147854447365,\n",
       " -0.004474646877497435,\n",
       " -0.0018644361989572644,\n",
       " -0.016120020300149918,\n",
       " -0.011744183488190174,\n",
       " 0.0031783636659383774,\n",
       " -0.026687903329730034,\n",
       " 0.020251188427209854,\n",
       " -0.024090632796287537,\n",
       " -0.00855876225978136,\n",
       " -0.004112346097826958,\n",
       " -0.018943142145872116,\n",
       " 0.007895328104496002,\n",
       " 0.031995370984077454,\n",
       " 0.01868906058371067,\n",
       " -0.04987513646483421,\n",
       " 0.022547326982021332,\n",
       " 0.01116073876619339,\n",
       " 0.01632704958319664,\n",
       " -0.033049337565898895,\n",
       " 0.00023070191673468798,\n",
       " -0.02506931498646736,\n",
       " 0.013560391031205654,\n",
       " -0.004338196013122797,\n",
       " 0.013362772762775421,\n",
       " -0.004030005075037479,\n",
       " 0.0215310025960207,\n",
       " 4.488321428652853e-05,\n",
       " -0.0036818203516304493,\n",
       " -0.005759167019277811,\n",
       " -0.038657937198877335,\n",
       " 0.012045316398143768,\n",
       " -0.025539834052324295,\n",
       " 0.045282863080501556,\n",
       " -0.021380435675382614,\n",
       " -0.015508344396948814,\n",
       " -0.027497198432683945,\n",
       " -0.06606103479862213,\n",
       " 0.0262173842638731,\n",
       " -0.014369686134159565,\n",
       " 0.011584206484258175,\n",
       " -0.0136544955894351,\n",
       " 0.021060483530163765,\n",
       " 0.018340876325964928,\n",
       " -0.00852582510560751,\n",
       " 0.005439213011413813,\n",
       " -0.004754606168717146,\n",
       " -0.0028795835096389055,\n",
       " -0.04050237685441971,\n",
       " 0.03997539356350899,\n",
       " 0.03990010917186737,\n",
       " -0.00850700493901968,\n",
       " 0.021418077871203423,\n",
       " 0.012158241122961044,\n",
       " -0.0030654389411211014,\n",
       " 0.006582577247172594,\n",
       " -0.003164248075336218,\n",
       " -0.04554635286331177,\n",
       " -0.03122371807694435,\n",
       " 0.03425386920571327,\n",
       " -0.0032371787820011377,\n",
       " -0.05085381865501404,\n",
       " 0.03929784521460533,\n",
       " -0.006229687016457319,\n",
       " -0.017569223418831825,\n",
       " -0.043137289583683014,\n",
       " 0.0370958112180233,\n",
       " -0.0065025887452065945,\n",
       " -0.003103080438449979,\n",
       " 0.021926239132881165,\n",
       " -0.05187014490365982,\n",
       " 0.00557566387578845,\n",
       " -0.015856530517339706,\n",
       " 0.027196066454052925,\n",
       " 0.01326866913586855,\n",
       " -0.017588043585419655,\n",
       " 0.008384669199585915,\n",
       " -0.010492599569261074,\n",
       " 0.0046369764022529125,\n",
       " 0.0034583231899887323,\n",
       " -0.0027172539848834276,\n",
       " -0.017381014302372932,\n",
       " -0.028852296993136406,\n",
       " 0.05111731216311455,\n",
       " 0.011508923023939133,\n",
       " -0.012092368677258492,\n",
       " 0.023206055164337158,\n",
       " 0.024918748065829277,\n",
       " -0.0026043292600661516,\n",
       " 0.005302762147039175,\n",
       " -0.03235296532511711,\n",
       " -0.0028631151653826237,\n",
       " -0.0023502481635659933,\n",
       " -0.03660646826028824,\n",
       " 0.00011924745922442526,\n",
       " 0.019686564803123474,\n",
       " -0.009523328393697739,\n",
       " 0.02200152352452278,\n",
       " -0.03094140626490116,\n",
       " -0.02488110587000847,\n",
       " 0.002402005484327674,\n",
       " -0.03485613316297531,\n",
       " -0.05269825831055641,\n",
       " 0.023526009172201157,\n",
       " 0.015197801403701305,\n",
       " -0.00928336288779974,\n",
       " -0.0317695215344429,\n",
       " 0.0032889361027628183,\n",
       " -0.02452351152896881,\n",
       " -0.027817152440547943,\n",
       " 0.009937386028468609,\n",
       " -0.03214593976736069,\n",
       " 0.009358646348118782,\n",
       " -0.025822147727012634,\n",
       " 0.016637593507766724,\n",
       " -0.006662565749138594,\n",
       " -0.012807559221982956,\n",
       " 0.010389085859060287,\n",
       " -0.014341454952955246,\n",
       " 0.001749158720485866,\n",
       " 0.005872091744095087,\n",
       " 0.03937312960624695,\n",
       " 0.01717398688197136,\n",
       " -0.00401588948443532,\n",
       " -0.011386588215827942,\n",
       " 0.007142496295273304,\n",
       " -0.014002680778503418,\n",
       " -0.004865178372710943,\n",
       " -0.014059143140912056,\n",
       " 0.02399652823805809,\n",
       " -0.029416920617222786,\n",
       " -0.0005143373855389655,\n",
       " 0.022697893902659416,\n",
       " -0.04863296449184418,\n",
       " -0.017926817759871483,\n",
       " 0.020025338977575302,\n",
       " 0.007580080069601536,\n",
       " -0.026123279705643654,\n",
       " -0.010153825394809246,\n",
       " -0.012384090572595596,\n",
       " -0.01086901593953371,\n",
       " 0.021041661500930786,\n",
       " 0.0031313118524849415,\n",
       " 0.015837708488106728,\n",
       " -0.011461871676146984,\n",
       " 0.00473343301564455,\n",
       " -0.017381014302372932,\n",
       " 0.03551486134529114,\n",
       " 0.0010621992405503988,\n",
       " 0.011038403026759624,\n",
       " -0.04102936014533043,\n",
       " -0.01019146665930748,\n",
       " -0.01547070313245058,\n",
       " -0.023563649505376816,\n",
       " 0.01076550129801035,\n",
       " 0.038375623524188995,\n",
       " 0.01606355793774128,\n",
       " -0.017126934602856636,\n",
       " 0.017907997593283653,\n",
       " 0.03681349754333496,\n",
       " 0.017079882323741913,\n",
       " 0.03319990262389183,\n",
       " -0.030207395553588867,\n",
       " 0.0003152485005557537,\n",
       " -0.00717543251812458,\n",
       " -0.013569802045822144,\n",
       " -0.01812443695962429,\n",
       " -0.008252923376858234,\n",
       " -0.006662565749138594,\n",
       " -0.019592460244894028,\n",
       " -0.006008542608469725,\n",
       " -0.02702667936682701,\n",
       " -0.03180716186761856,\n",
       " -0.026932574808597565,\n",
       " 0.03937312960624695,\n",
       " -0.0223026555031538,\n",
       " -0.004556987900286913,\n",
       " -0.0314495675265789,\n",
       " 0.027139604091644287,\n",
       " -0.0013609796296805143,\n",
       " -0.014539073221385479,\n",
       " -0.02757248282432556,\n",
       " -0.02817474864423275,\n",
       " -0.004199392627924681,\n",
       " -0.00020394109014887363,\n",
       " 0.015433061867952347,\n",
       " -0.02900286391377449,\n",
       " -0.004415831994265318,\n",
       " -0.02843823842704296,\n",
       " -0.020721707493066788,\n",
       " -0.045282863080501556,\n",
       " -0.015583627857267857,\n",
       " -0.04637446999549866,\n",
       " -0.028099464252591133,\n",
       " -0.019743027165532112,\n",
       " 0.041970398277044296,\n",
       " -0.008784611709415913,\n",
       " -0.005919143557548523,\n",
       " -0.005777987651526928,\n",
       " -0.0031219013035297394,\n",
       " -0.007645952980965376,\n",
       " -0.05239712446928024,\n",
       " -0.003757103579118848,\n",
       " -0.02510695718228817,\n",
       " 0.007368345744907856,\n",
       " 0.021286332979798317,\n",
       " -0.01725867949426174,\n",
       " 0.019686564803123474,\n",
       " -0.022208552807569504,\n",
       " 0.010821963660418987,\n",
       " 0.014651997946202755,\n",
       " 0.022660251706838608,\n",
       " -0.02791125699877739,\n",
       " -0.007373051252216101,\n",
       " -0.0552578903734684,\n",
       " 0.04012595862150192,\n",
       " -0.05548373982310295,\n",
       " -0.00019335438264533877,\n",
       " -0.013023998588323593,\n",
       " -0.0038018031045794487,\n",
       " -0.009927975945174694,\n",
       " -0.0009192787692882121,\n",
       " -0.004135872237384319,\n",
       " -0.025182239711284637,\n",
       " 0.04471823573112488,\n",
       " -0.028024181723594666,\n",
       " 0.011913570575416088,\n",
       " 0.023488366976380348,\n",
       " 0.04102936014533043,\n",
       " 0.022377939894795418,\n",
       " 0.03967425972223282,\n",
       " -0.023657754063606262,\n",
       " 0.020270008593797684,\n",
       " -0.012760506942868233,\n",
       " 0.002917225006967783,\n",
       " -0.0389590710401535,\n",
       " 0.018152669072151184,\n",
       " 0.02456115372478962,\n",
       " -0.027723047882318497,\n",
       " -0.03598538413643837,\n",
       " -0.04151869937777519,\n",
       " -0.019121939316391945,\n",
       " -0.00948568619787693,\n",
       " 0.019987696781754494,\n",
       " -0.018980784341692924,\n",
       " -0.012177062220871449,\n",
       " -0.0339527353644371,\n",
       " -0.00013740659051109105,\n",
       " 0.01951717585325241,\n",
       " -0.01560244895517826,\n",
       " -0.006300264969468117,\n",
       " -0.02759130299091339,\n",
       " 0.02484346553683281,\n",
       " 0.005599190015345812,\n",
       " -0.0014362628571689129,\n",
       " 0.03479967266321182,\n",
       " 0.03301169350743294,\n",
       " 0.01600709557533264,\n",
       " 0.019385430961847305,\n",
       " -0.011123096570372581,\n",
       " 0.03442325443029404,\n",
       " 0.012807559221982956,\n",
       " -0.009730356745421886,\n",
       " -0.041706908494234085,\n",
       " -0.002764306031167507,\n",
       " -0.024768181145191193,\n",
       " -0.009631548076868057,\n",
       " 0.014426148496568203,\n",
       " -0.003441855078563094,\n",
       " -0.02595389261841774,\n",
       " -0.021418077871203423,\n",
       " -0.009636253118515015,\n",
       " 0.01383329275995493,\n",
       " 0.05431684851646423,\n",
       " -0.02738427370786667,\n",
       " -0.011452460661530495,\n",
       " 0.03440443426370621,\n",
       " 0.0009786819573491812,\n",
       " 0.013889755122363567,\n",
       " 0.015310726128518581,\n",
       " 0.039486054331064224,\n",
       " 0.006408484652638435,\n",
       " 0.029416920617222786,\n",
       " 0.025878610089421272,\n",
       " 0.06350140273571014,\n",
       " -0.008742264471948147,\n",
       " -0.01201708521693945,\n",
       " 0.010972530581057072,\n",
       " -0.016270587220788002,\n",
       " 0.011330125853419304,\n",
       " 0.01438850723206997,\n",
       " -0.028551163151860237,\n",
       " -0.026612620800733566,\n",
       " 0.0063896640203893185,\n",
       " 0.02346954680979252,\n",
       " -0.008069421164691448,\n",
       " -0.00370064121671021,\n",
       " 0.005599190015345812,\n",
       " 0.001253936206921935,\n",
       " 0.025765685364603996,\n",
       " -0.017550403252243996,\n",
       " 0.02960512973368168,\n",
       " -0.035044342279434204,\n",
       " 0.01228057686239481,\n",
       " 0.00857758242636919,\n",
       " -0.023017846047878265,\n",
       " -0.013692136853933334,\n",
       " -0.0022784939501434565,\n",
       " -0.026706725358963013,\n",
       " 0.021116945892572403,\n",
       " -0.009241016581654549,\n",
       " -0.02510695718228817,\n",
       " 0.022641431540250778,\n",
       " -0.009758587926626205,\n",
       " -0.018877269700169563,\n",
       " 0.07223425805568695,\n",
       " -0.03707699105143547,\n",
       " 0.04874588921666145,\n",
       " 0.028532342985272408,\n",
       " -0.06000073254108429,\n",
       " 0.04325021430850029,\n",
       " 0.042572665959596634,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use the SILICONFLOW BAAI embedding model instead.\n",
    "# Note infini-ai's embedding model has some issues, so we do not use it here.\n",
    "# Don't forget to set the environment variable SILICONFLOW_API_KEY!!!\n",
    "\n",
    "import os\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "baai_embedding = OpenAIEmbeddings(\n",
    "    model=\"BAAI/bge-m3\",\n",
    "    base_url=os.environ.get(\"SF_BASE_URL\"),\n",
    "    api_key=os.environ.get(\"SF_API_KEY\"),\n",
    ")\n",
    "baai_embedding.embed_query(\"Harry Potter is a wizard.\") # test the embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b805c79-c5b1-4812-9b85-671820ff0a69",
   "metadata": {},
   "source": [
    "### 2.4  Store and retrieve the embeddings in ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c0c49f-541a-44da-8f5b-1e6059b478a6",
   "metadata": {},
   "source": [
    "You can search documents stored in \"Vector DBs\" by their semantic similarity.  Vector DBs uses an algorithm called \"KNN (k-nearest neighbors)\" to find documents whose embedding is the closest to the query. \n",
    "\n",
    "We first introduce ChromaDB becauase it runs locally, easy-to-set-up, and best of all, free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2af187c9-e90d-40be-a74f-db620af2bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute embeddings and save the embeddings into ChromaDB\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "chroma_dir = \"/scratch1/chroma_db\"\n",
    "docsearch_chroma = Chroma(\n",
    "    embedding_function=baai_embedding,\n",
    "    persist_directory=chroma_dir,\n",
    "    collection_name=\"harry-potter\",\n",
    ")\n",
    "docsearch_chroma.reset_collection()\n",
    "# docsearch_chroma.add_documents(texts)\n",
    "for t in texts:\n",
    "    docsearch_chroma.add_documents([t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51465f59-49ed-45a5-832a-1f03b9560c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# questions from https://en.wikibooks.org/wiki/Muggles%27_Guide_to_Harry_Potter/Books/Philosopher%27s_Stone/Chapter_1\n",
    "# you can try yourself\n",
    "\n",
    "# query = 'Why would the Dursleys consider being related to the Potters a \"shameful secret\"?'\n",
    "# query = 'Who are the robed people Mr. Dursley sees in the streets?'\n",
    "# query = 'What might a \"Muggle\" be?'\n",
    "query = '''Who might \"You-Know-Who\" be? Why isn't this person referred to by a given name?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34cf7c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## A utiity function ...\n",
    "def print_search_results(docs):\n",
    "    print(f\"search returned %d results. \" % len(docs))\n",
    "    for doc in docs:\n",
    "        print(doc.page_content)\n",
    "        print(\"=============\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c24069d5-19d6-477b-a3ba-c79b6cd39d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "\"No, thank you,\" said Professor McGonagall coldly, as though she didn't  \n",
      "think this was the moment for lemon drops. \"As I say, even if  \n",
      "You-Know-Who has gone -\" \n",
      " \n",
      "\"My dear Professor, surely a sensible person like yourself can call him  \n",
      "by his name? All this 'You- Know-Who' nonsense -- for eleven years I \n",
      "have been trying to persuade people to call him by his proper name:  \n",
      "Voldemort.\" Professor McGonagall flinched, but Dumbledore, who was  \n",
      "unsticking two lemon drops, seemed not to notice. \"It all gets so  \n",
      "confusing if we keep saying 'You -Know-Who.' I have never seen any \n",
      "reason \n",
      "to be frightened of saying Voldemort's name.  \n",
      " \n",
      "\"I know you haven 't, said Professor McGonagall, sounding half  \n",
      "exasperated, half admiring. \"But you're different. Everyone knows you're\n",
      "=============\n",
      "half-moon glasses. \"It would be enough to turn any boy's head. Famous  \n",
      "before he can walk and talk! Famous for something he won't even  \n",
      "remember! CarA you see how much better off he'll be, growing up away  \n",
      "from all that until he's ready to tak e it?\"\n",
      "=============\n",
      "It had twelve hands but no numbers; instead, little planets were moving  \n",
      "around the edge. It must have made sense to Dumbledore, though, because  \n",
      "he put it back in his pocket and said, \"Hagrid's late. I suppose it was  \n",
      "he who told you I'd be here, by the way?\"  \n",
      " \n",
      "\"Yes,\" said Professor McGonagall. \"And I don't suppose you're going to  \n",
      "tell me why you're here, of all places?\"  \n",
      " \n",
      "\"I've come to bring Harry to his aunt and uncle. They're the only family  \n",
      "he has left now.\" \n",
      " \n",
      "\"You don't mean -- you can't mean the people who live here?\" cried  \n",
      "Professor McGonagall, jumping to her feet and pointing at number four.  \n",
      "\"Dumbledore -- you can't. I've been watching them all day. You couldn't  \n",
      "find two people who are less like us. And  they've got this son -- I saw\n",
      "=============\n",
      "and it didn't improve his mood -- was the tabby cat he'd spotted that  \n",
      "morning. It was now sitting on his garden wall. He was sure it was the  \n",
      "same one; it had the same markings around  its eyes. \n",
      " \n",
      "\"Shoo!\" said Mr. Dursley loudly. The cat didn't move. It just gave him a  \n",
      "stern look. Was this normal cat behavior? Mr. Dursley wondered. Trying\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# semantic similarity search\n",
    "\n",
    "docs = docsearch_chroma.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a21737",
   "metadata": {},
   "source": [
    "#### Saving and Loading your ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd053d53-d5a0-4e1f-8d56-69acb51d6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload from disk\n",
    "docsearch_chroma_reloaded = Chroma(persist_directory = chroma_dir,\n",
    "                                   collection_name = 'harry-potter', \n",
    "                                   embedding_function = baai_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1f853-d04e-4bae-8bf2-bddec2d4326e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 6 results. \n",
      "Drive, but there wasn't a map in sight. What could he have been thinking  \n",
      "of? It must have been a trick of the light. Mr. Dursley blinked and  \n",
      "stared at the cat. It stared back. As Mr. Dursley drove around the  \n",
      "corner and up the road, he watched the cat in his mirror. It was now  \n",
      "reading the sign that said Privet Drive -- no, looking at the sign; cats \n",
      "couldn't read maps or signs. Mr. Dursley gave himself a little shake and  \n",
      "put the cat out of his mind. As he drove toward town he thought of  \n",
      "nothing except a large order of drills he was hoping to get that day.  \n",
      " \n",
      "But on the edge of town, drills were driven out of his mind by something  \n",
      "else. As he sat in the usual morning tr affic jam, he couldn't help \n",
      "noticing that there seemed to be a lot of strangely dressed people\n",
      "=============\n",
      "As he had expected, Mrs. Dursley looked shocked and angry. After all,  \n",
      "they normally pretended she didn't have a sister.  \n",
      " \n",
      "\"No,\" she said sharply. \"Why?\" \n",
      " \n",
      "\"Funny stuff on the news,\" Mr. Dursley mumbled. \"Owls... shooting  \n",
      "stars... and there were a lot of funny -looking people in town today...\" \n",
      " \n",
      "\"So?\" snapped Mrs. Dursley. \n",
      " \n",
      "\"Well, I just thought... maybe... it was something to do with... you  \n",
      "know... her crowd.\" \n",
      " \n",
      "Mrs. Dursley sipped her tea through pursed lips. Mr. Dursley wondered  \n",
      "whether he dared tell her he'd heard the name \"Potter.\" He decided he \n",
      "didn't dare. Instead he said, as casually as he could, \"Their son -- \n",
      "he'd be about Dudley's age now, wouldn't he?\"  \n",
      " \n",
      "\"I suppose so,\" said Mrs. Dursley stiffly.  \n",
      " \n",
      "\"What's his name again? Howard, isn't it?\"\n",
      "=============\n",
      "and it didn't improve his mood -- was the tabby cat he'd spotted that  \n",
      "morning. It was now sitting on his garden wall. He was sure it was the  \n",
      "same one; it had the same markings around  its eyes. \n",
      " \n",
      "\"Shoo!\" said Mr. Dursley loudly. The cat didn't move. It just gave him a  \n",
      "stern look. Was this normal cat behavior? Mr. Dursley wondered. Trying\n",
      "=============\n",
      "sunrise. Experts are unable to explain why the owls have suddenly  \n",
      "changed their sleeping pattern.\" The newscaster allowed himself a grin. \n",
      "\"Most mysterious. And now, over to Jim McGuffin with the weather. \n",
      "Going \n",
      "to be any more showers of owls tonight, Jim?\"  \n",
      " \n",
      "\"Well, Ted,\" said the weatherman, \"I don't know about that, but it's not  \n",
      "only the owls that have been acting oddly today. View ers as far apart as \n",
      "Kent, Yorkshire, and Dundee have been phoning in to tell me that instead  \n",
      "of the rain I promised yesterday, they've had a downpour of shooting  \n",
      "stars! Perhaps people have been celebrating Bonfire Night early -- it's \n",
      "not until next week, folks! But I can promise a wet night tonight.\"  \n",
      " \n",
      "Mr. Dursley sat frozen in his armchair. Shooting stars all over Britain?\n",
      "=============\n",
      "Dumbledore with such a piercin g stare as she did now. It was plain that  \n",
      "whatever \"everyone\" was saying, she was not going to believe it until  \n",
      "Dumbledore told her it was true. Dumbledore, however, was choosing  \n",
      "another lemon drop and did not answer.  \n",
      " \n",
      "\"What they're saying,\" she pressed on, \"is that last night Voldemort  \n",
      "turned up in Godric's Hollow. He went to find the Potters. The rumor is  \n",
      "that Lily and James Potter are -- are -- that they're -- dead. \" \n",
      " \n",
      "Dumbledore bowed his head. Professor McGonagall gasped.  \n",
      " \n",
      "\"Lily and James... I can't believe it... I didn't want to believe it...  \n",
      "Oh, Albus...\" \n",
      " \n",
      "Dumbledore reached out and patted her on the shoulder. \"I know... I  \n",
      "know...\" he said heavily. \n",
      " \n",
      "Professor McGonagall's voice trembled as she went on. \"That's not all.\n",
      "=============\n",
      "It had twelve hands but no numbers; instead, little planets were moving  \n",
      "around the edge. It must have made sense to Dumbledore, though, because  \n",
      "he put it back in his pocket and said, \"Hagrid's late. I suppose it was  \n",
      "he who told you I'd be here, by the way?\"  \n",
      " \n",
      "\"Yes,\" said Professor McGonagall. \"And I don't suppose you're going to  \n",
      "tell me why you're here, of all places?\"  \n",
      " \n",
      "\"I've come to bring Harry to his aunt and uncle. They're the only family  \n",
      "he has left now.\" \n",
      " \n",
      "\"You don't mean -- you can't mean the people who live here?\" cried  \n",
      "Professor McGonagall, jumping to her feet and pointing at number four.  \n",
      "\"Dumbledore -- you can't. I've been watching them all day. You couldn't  \n",
      "find two people who are less like us. And  they've got this son -- I saw\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# you can test with the previous or another query\n",
    "\n",
    "query = 'Who are the robed people Mr. Dursley sees in the streets?'\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query, k=6)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8cdb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded book with 327 pages\n",
      "\n",
      "Testing RecursiveCharacterTextSplitter with chunk_size=500, overlap=50\n",
      "Created 12 chunks from 3 pages\n",
      "Sample chunk (439 chars):\n",
      "THE  BOY  WHO  LIVED \n",
      " 3  \n",
      "of Privet Drive, but there wasn’t  a map in sight. What could he \n",
      "have been thinking of? It must have  been a trick of th...\n",
      "\n",
      "Testing RecursiveCharacterTextSplitter with chunk_size=500, overlap=150\n",
      "Created 16 chunks from 3 pages\n",
      "Sample chunk (439 chars):\n",
      "THE  BOY  WHO  LIVED \n",
      " 3  \n",
      "of Privet Drive, but there wasn’t  a map in sight. What could he \n",
      "have been thinking of? It must have  been a trick of th...\n",
      "\n",
      "Testing RecursiveCharacterTextSplitter with chunk_size=500, overlap=300\n",
      "Created 23 chunks from 3 pages\n",
      "Sample chunk (439 chars):\n",
      "THE  BOY  WHO  LIVED \n",
      " 3  \n",
      "of Privet Drive, but there wasn’t  a map in sight. What could he \n",
      "have been thinking of? It must have  been a trick of th...\n",
      "\n",
      "Testing RecursiveCharacterTextSplitter with chunk_size=1000, overlap=50\n",
      "Created 6 chunks from 3 pages\n",
      "Sample chunk (936 chars):\n",
      "THE  BOY  WHO  LIVED \n",
      " 3  \n",
      "of Privet Drive, but there wasn’t  a map in sight. What could he \n",
      "have been thinking of? It must have  been a trick of th...\n",
      "\n",
      "Testing RecursiveCharacterTextSplitter with chunk_size=1000, overlap=150\n",
      "Created 7 chunks from 3 pages\n",
      "Sample chunk (936 chars):\n",
      "THE  BOY  WHO  LIVED \n",
      " 3  \n",
      "of Privet Drive, but there wasn’t  a map in sight. What could he \n",
      "have been thinking of? It must have  been a trick of th...\n",
      "\n",
      "Testing RecursiveCharacterTextSplitter with chunk_size=1000, overlap=300\n",
      "Created 9 chunks from 3 pages\n",
      "Sample chunk (936 chars):\n",
      "THE  BOY  WHO  LIVED \n",
      " 3  \n",
      "of Privet Drive, but there wasn’t  a map in sight. What could he \n",
      "have been thinking of? It must have  been a trick of th...\n",
      "\n",
      "Testing RecursiveCharacterTextSplitter with chunk_size=1500, overlap=50\n",
      "Created 6 chunks from 3 pages\n",
      "Sample chunk (1461 chars):\n",
      "THE  BOY  WHO  LIVED \n",
      " 3  \n",
      "of Privet Drive, but there wasn’t  a map in sight. What could he \n",
      "have been thinking of? It must have  been a trick of th...\n",
      "\n",
      "Testing RecursiveCharacterTextSplitter with chunk_size=1500, overlap=150\n",
      "Created 6 chunks from 3 pages\n",
      "Sample chunk (1461 chars):\n",
      "THE  BOY  WHO  LIVED \n",
      " 3  \n",
      "of Privet Drive, but there wasn’t  a map in sight. What could he \n",
      "have been thinking of? It must have  been a trick of th...\n",
      "\n",
      "Testing RecursiveCharacterTextSplitter with chunk_size=1500, overlap=300\n",
      "Created 6 chunks from 3 pages\n",
      "Sample chunk (1461 chars):\n",
      "THE  BOY  WHO  LIVED \n",
      " 3  \n",
      "of Privet Drive, but there wasn’t  a map in sight. What could he \n",
      "have been thinking of? It must have  been a trick of th...\n",
      "\n",
      "CharacterTextSplitter created 0 chunks from 3 pages\n",
      "\n",
      "Splitting full book into 607 chunks with chunk_size=1000, overlap=150\n",
      "Adding chunks 0 to 49\n",
      "Adding chunks 50 to 99\n",
      "Adding chunks 100 to 149\n",
      "Adding chunks 150 to 199\n",
      "Adding chunks 200 to 249\n",
      "Adding chunks 250 to 299\n",
      "Adding chunks 300 to 349\n",
      "Adding chunks 350 to 399\n",
      "Adding chunks 400 to 449\n",
      "Adding chunks 450 to 499\n",
      "Adding chunks 500 to 549\n",
      "Adding chunks 550 to 599\n",
      "Adding chunks 600 to 606\n",
      "Successfully embedded full book into ChromaDB at /scratch1/full_hp_chroma_db\n",
      "\n",
      "Test query: What happens when Harry first meets Hagrid?\n",
      "search returned 3 results. \n",
      "tering nonstop under his breath. \n",
      "“He’s doing something — jinxing the broom,” said Hermione. \n",
      "“What should we do?” \n",
      "“Leave it to me.” \n",
      "Before Ron could say another word, Hermione had disappeared. \n",
      "Ron turned the binoculars back on Harry. His broom was vibrat-\n",
      "ing so hard, it was almost impossible for him to hang on much \n",
      "longer. The whole crowd was on its feet, watching, terrified, as \n",
      "the Weasleys flew up to try and pull Harry safely onto one of \n",
      "their brooms, but it was no good — every time they got near him, \n",
      "the broom would jump higher still. They dropped lower and cir-\n",
      "cled beneath him, obviously hoping to catch him if he fell. Marcus\n",
      "=============\n",
      "unseen.” \n",
      "Harry had a sudden idea. \n",
      "“Peeves,” he said, in a hoarse wh isper, “the Bloody Baron has his \n",
      "own reasons for being invisible.” \n",
      "Peeves almost fell out of the air in shock. He caught himself in \n",
      "time and hovered about a foot off the stairs. \n",
      "“So sorry, your bloodiness, Mr. Baron, sir,” he said greasily. “My \n",
      "mistake, my mistake — I didn’t see you — of co urse I didn’t, \n",
      "you’re invisible — forgive old Peevsie his little joke, sir.” \n",
      "“I have business here, Peeves,” croaked Harry. “Stay away from \n",
      "this place tonight.” \n",
      "“I will, sir, I most certainly will,” said Peeves, rising up in the air \n",
      "again. “Hope your business goes well, Baron, I’ll not bother you.” \n",
      "And he scooted off.\n",
      "=============\n",
      "whistled through the gaps in th e wooden walls, and the fireplace \n",
      "was damp and empty. Ther e were only two rooms. \n",
      "Uncle Vernon’s rations turned out to be a bag of chips each and \n",
      "four bananas. He tried to start a fire but the empty chip bags just \n",
      "smoked and shriveled up. \n",
      "“Could do with some of  those letters now, eh?” he said cheer-\n",
      "fully. \n",
      "He was in a very good mood. Ob viously he thought nobody \n",
      "stood a chance of reaching them here in a storm to deliver mail. \n",
      "Harry privately agreed, though th e thought didn’t cheer him up \n",
      "at all. \n",
      "As night fell, the promised stor m blew up around them. Spray \n",
      "from the high waves splattered the walls of the hut and a fierce\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "\n",
    "#### Your TASK ####\n",
    "# With the chosen PDF loaders, test different splitters and chunk size until you feel that the chucking makes sense. \n",
    "# You can also try different embeddings\n",
    "# Then embed the entire book 1 into ChormaDB\n",
    "\n",
    "# Load the full Harry Potter book\n",
    "hp_book_path = \"/ssdshare/share/lab4/hp-book1.pdf\"\n",
    "full_book = PyPDFLoader(hp_book_path).load()\n",
    "print(f\"Loaded book with {len(full_book)} pages\")\n",
    "\n",
    "# Test different text splitters and chunk sizes\n",
    "\n",
    "# First try RecursiveCharacterTextSplitter with different chunk sizes\n",
    "for chunk_size in [500, 1000, 1500]:\n",
    "    for chunk_overlap in [50, 150, 300]:\n",
    "        print(f\"\\nTesting RecursiveCharacterTextSplitter with chunk_size={chunk_size}, overlap={chunk_overlap}\")\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        chunks = splitter.split_documents(full_book[14:17])  # Test with first 3 pages\n",
    "        print(f\"Created {len(chunks)} chunks from 3 pages\")\n",
    "        \n",
    "        # Print a sample chunk to see how it looks\n",
    "        if chunks:\n",
    "            print(f\"Sample chunk ({len(chunks[0].page_content)} chars):\\n{chunks[0].page_content[:150]}...\")\n",
    "\n",
    "# Try CharacterTextSplitter for comparison\n",
    "char_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "char_chunks = char_splitter.split_documents(full_book[:3])\n",
    "print(f\"\\nCharacterTextSplitter created {len(char_chunks)} chunks from 3 pages\")\n",
    "\n",
    "# Based on the tests, choose the best splitter and parameters\n",
    "# Let's use RecursiveCharacterTextSplitter with chunk_size=1000 and chunk_overlap=150\n",
    "chosen_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)\n",
    "all_chunks = chosen_splitter.split_documents(full_book)\n",
    "print(f\"\\nSplitting full book into {len(all_chunks)} chunks with chunk_size=1000, overlap=150\")\n",
    "\n",
    "# Create a new ChromaDB collection for the full book\n",
    "full_book_chroma_dir = \"/scratch1/full_hp_chroma_db\"\n",
    "full_book_chroma = Chroma(\n",
    "    embedding_function=baai_embedding,\n",
    "    persist_directory=full_book_chroma_dir,\n",
    "    collection_name=\"harry-potter-full\",\n",
    ")\n",
    "full_book_chroma.reset_collection()\n",
    "\n",
    "# Embed and store chunks in batches to avoid memory issues\n",
    "batch_size = 50\n",
    "for i in range(0, len(all_chunks), batch_size):\n",
    "    batch_end = min(i + batch_size, len(all_chunks))\n",
    "    print(f\"Adding chunks {i} to {batch_end-1}\")\n",
    "    full_book_chroma.add_documents(all_chunks[i:batch_end])\n",
    "\n",
    "print(f\"Successfully embedded full book into ChromaDB at {full_book_chroma_dir}\")\n",
    "\n",
    "# Test a query to verify the embedding quality\n",
    "test_query = \"What happens when Harry first meets Hagrid?\"\n",
    "results = full_book_chroma.similarity_search(test_query, k=3)\n",
    "print(f\"\\nTest query: {test_query}\")\n",
    "print_search_results(results)\n",
    "\n",
    "\n",
    "# the code is generated by copilot (Claude 3.7 Sonnet Thinking), using prompt \"finish the task\". I modified the test pages to 14-16 (the original code selected 0-2, which do not contain text)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa211d6-014a-4b99-8c79-1699557e0fe1",
   "metadata": {},
   "source": [
    "### 2.5 Query those docs with a QA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f035d818-b8cf-4d49-9a6f-ba233e204188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0, model=CHAT_MODEL)\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    chain_type=\"stuff\", \n",
    "    verbose=True, \n",
    "    retriever=docsearch_chroma_reloaded.as_retriever(k=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db75a21-9f02-4e09-98ef-81c40d6e04a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 4 results. \n",
      "twelve balls of light sped back to their street lamps so that Privet  \n",
      "Drive glowed suddenly orange and he could make out a tabby cat slinking  \n",
      "around the corner at the other end of the street. He could just see the  \n",
      "bundle of blankets on the step of number four.  \n",
      " \n",
      "\"Good luck, Harry,\" he murmured. He turned on his heel and with a swish  \n",
      "of his cloak, he was gone.\n",
      "=============\n",
      "Drive, but there wasn't a map in sight. What could he have been thinking  \n",
      "of? It must have been a trick of the light. Mr. Dursley blinked and  \n",
      "stared at the cat. It stared back. As Mr. Dursley drove around the  \n",
      "corner and up the road, he watched the cat in his mirror. It was now  \n",
      "reading the sign that said Privet Drive -- no, looking at the sign; cats \n",
      "couldn't read maps or signs. Mr. Dursley gave himself a little shake and  \n",
      "put the cat out of his mind. As he drove toward town he thought of  \n",
      "nothing except a large order of drills he was hoping to get that day.  \n",
      " \n",
      "But on the edge of town, drills were driven out of his mind by something  \n",
      "else. As he sat in the usual morning tr affic jam, he couldn't help \n",
      "noticing that there seemed to be a lot of strangely dressed people\n",
      "=============\n",
      "and it didn't improve his mood -- was the tabby cat he'd spotted that  \n",
      "morning. It was now sitting on his garden wall. He was sure it was the  \n",
      "same one; it had the same markings around  its eyes. \n",
      " \n",
      "\"Shoo!\" said Mr. Dursley loudly. The cat didn't move. It just gave him a  \n",
      "stern look. Was this normal cat behavior? Mr. Dursley wondered. Trying\n",
      "=============\n",
      "sunrise. Experts are unable to explain why the owls have suddenly  \n",
      "changed their sleeping pattern.\" The newscaster allowed himself a grin. \n",
      "\"Most mysterious. And now, over to Jim McGuffin with the weather. \n",
      "Going \n",
      "to be any more showers of owls tonight, Jim?\"  \n",
      " \n",
      "\"Well, Ted,\" said the weatherman, \"I don't know about that, but it's not  \n",
      "only the owls that have been acting oddly today. View ers as far apart as \n",
      "Kent, Yorkshire, and Dundee have been phoning in to tell me that instead  \n",
      "of the rain I promised yesterday, they've had a downpour of shooting  \n",
      "stars! Perhaps people have been celebrating Bonfire Night early -- it's \n",
      "not until next week, folks! But I can promise a wet night tonight.\"  \n",
      " \n",
      "Mr. Dursley sat frozen in his armchair. Shooting stars all over Britain?\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "# query = \"How did Harry's parents die?\"\n",
    "query = \"What is the cat on Privet Drive?\"\n",
    "docs = docsearch_chroma_reloaded.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98270f41-fddd-4be0-909d-c80345e98470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'What is the cat on Privet Drive?',\n",
       " 'result': \"The cat on Privet Drive is described as a tabby cat with distinctive markings around its eyes. It is later revealed in the Harry Potter series that this cat is actually Professor Minerva McGonagall, who is a witch and a Transfiguration teacher at Hogwarts School of Witchcraft and Wizardry. She is observing the Dursleys' house in her Animagus form, which allows her to transform into a cat.\"}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0d396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents retrieved by similarity search:\n",
      "search returned 4 results. \n",
      "tering nonstop under his breath. \n",
      "“He’s doing something — jinxing the broom,” said Hermione. \n",
      "“What should we do?” \n",
      "“Leave it to me.” \n",
      "Before Ron could say another word, Hermione had disappeared. \n",
      "Ron turned the binoculars back on Harry. His broom was vibrat-\n",
      "ing so hard, it was almost impossible for him to hang on much \n",
      "longer. The whole crowd was on its feet, watching, terrified, as \n",
      "the Weasleys flew up to try and pull Harry safely onto one of \n",
      "their brooms, but it was no good — every time they got near him, \n",
      "the broom would jump higher still. They dropped lower and cir-\n",
      "cled beneath him, obviously hoping to catch him if he fell. Marcus\n",
      "=============\n",
      "before. She let Harry watch televisi on and gave him a bit of choco-\n",
      "late cake that tasted as though  she’d had it for several years. \n",
      "That evening, Dudley paraded ar ound the living room for the \n",
      "family in his brand-new uniform. Smeltings boys wore maroon \n",
      "tailcoats, orange knickerbockers, an d flat straw hats called boaters. \n",
      "They also carried knobbly sticks, used for hitting each other while \n",
      "the teachers weren’t lo oking. This was suppo sed to be good train-\n",
      "ing for later life. \n",
      "As he looked at Dudley in his new knickerbockers, Uncle Ver-\n",
      "non said gruffly that it was the pr oudest moment of his life. Aunt \n",
      "Petunia burst into tears and said she couldn’t believe it was her Ickle \n",
      "Dudleykins, he looked so handsome and grown-up. Harry didn’t \n",
      "trust himself to speak. He thought two of his ribs might already \n",
      "have cracked from trying not to laugh. \n",
      "        \n",
      "=============\n",
      "struggle because the moment she had landed, the plant had started \n",
      "to twist snakelike tendrils arou nd her ankles. As for Harry and \n",
      "Ron, their legs had already been  bound tightly in long creepers \n",
      "without their noticing. \n",
      "Hermione had managed to free he rself before the plant got a \n",
      "firm grip on her. Now she watched in horror as the two boys fought \n",
      "to pull the plant off them, but the more they strained against it, the \n",
      "tighter and faster the pl ant wound around them. \n",
      "“Stop moving!” Hermione ordered them. “I know what this \n",
      "is — it’s Devil’s Snare!” \n",
      "“Oh, I’m so glad we know what it ’s called, that’s a great help,” \n",
      "snarled Ron, leaning back, trying to stop the plant from curling \n",
      "around his neck.\n",
      "=============\n",
      "C H A P T E R  E I G H T \n",
      " \n",
      " 131  \n",
      "THE POTIONS MASTER \n",
      " \n",
      " \n",
      " \n",
      "here, look.” \n",
      "“Where?” \n",
      "“Next to the tall kid with the red hair.” \n",
      "“Wearing the glasses?” \n",
      "“Did you see his face?” \n",
      "“Did you see his scar?” \n",
      "Whispers followed Harry from th e moment he left his dormi-\n",
      "tory the next day. People lining up outside classrooms stood on tip-\n",
      "toe to get a look at him, or dou bled back to pass him in the \n",
      "corridors again, staring. Harry wished they wouldn’t, because he \n",
      "was trying to concen trate on finding his way to classes. \n",
      "There were a hundred and forty- two staircases at Hogwarts: \n",
      "wide, sweeping ones; narrow, rick ety ones; some that led some-\n",
      "where different on a Friday; some with a vanishing step halfway up \n",
      "that you had to remember to jump. Then there were doors that  \n",
      " \n",
      "T\n",
      "=============\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final answer:\n",
      "{'query': 'Why is Harry left with the Dursleys rather than a Wizard family?', 'result': \"Harry is left with the Dursleys, his non-magical (Muggle) relatives, because of the protection it provides him. After the death of his parents, Lily and James Potter, at the hands of Lord Voldemort, Albus Dumbledore decides that Harry should live with his aunt Petunia (Lily's sister) and her family. \\n\\nThis arrangement ensures that Harry is protected by the powerful magical bond of blood. Because Petunia is Lily's sister, the love and sacrifice Lily made to protect Harry extends to Petunia's home, creating a protective charm that keeps Harry safe from Voldemort and his followers as long as he calls the Dursleys' house his home. \\n\\nAdditionally, Dumbledore believes it is important for Harry to grow up away from the fame and expectations of the wizarding world, allowing him to have a more normal childhood—though the Dursleys' treatment of him is far from ideal. \\n\\nThis decision is explained in *Harry Potter and the Philosopher's Stone* (or *Sorcerer's Stone* in the U.S.) and further explored in later books.\"}\n"
     ]
    }
   ],
   "source": [
    "#### Your Task ####\n",
    "# Rebuild the chain from the whole book ChromaDB.  Test with one of the following questions (of your choice).\n",
    "#query = 'Why does Dumbledore believe the celebrations may be premature?'\n",
    "#query = 'Why is Harry left with the Dursleys rather than a Wizard family?'\n",
    "#query = 'Why does McGonagall seem concerned about Harry being raised by the Dursleys?'\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "full_book_chroma_dir = \"/scratch1/full_hp_chroma_db\"\n",
    "full_book_chroma = Chroma(\n",
    "    embedding_function=baai_embedding,\n",
    "    persist_directory=full_book_chroma_dir,\n",
    "    collection_name=\"harry-potter-full\",\n",
    ")\n",
    "# Create a QA chain with the full book ChromaDB\n",
    "full_book_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm, \n",
    "    chain_type=\"stuff\", \n",
    "    verbose=True, \n",
    "    retriever=full_book_chroma.as_retriever(k=5)\n",
    ")\n",
    "\n",
    "# Choose one of the provided questions\n",
    "query = 'Why is Harry left with the Dursleys rather than a Wizard family?'\n",
    "\n",
    "# Get the relevant documents\n",
    "relevant_docs = full_book_chroma.similarity_search(query)\n",
    "print(\"Documents retrieved by similarity search:\")\n",
    "print_search_results(relevant_docs)\n",
    "\n",
    "# Run the query through the QA chain\n",
    "result = full_book_qa_chain.invoke(query)\n",
    "print(\"\\nFinal answer:\")\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n",
    "# the code is generated by copilot (Claude 3.7 Sonnet Thinking), using prompt \"finish the task\". The output is not modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4599ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MapReduceDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is an excerpt from Harry Potter:\n",
      "The  Vanishing  Glass \n",
      " 19  \n",
      "Yet Harry Potter was still there, asleep at the moment, but not \n",
      "for long. His Aunt Petunia was aw ake and it was her shrill voice \n",
      "that made the first noise of the day. \n",
      "“Up! Get up! Now!” \n",
      "Harry woke with a st art. His aunt rapped  on the door again. \n",
      "“Up!” she screeched. Harry heard her walking toward the \n",
      "kitchen and then the sound of th e frying pan being put on the \n",
      "stove. He rolled onto his back an d tried to remember the dream he \n",
      "had been having. It ha d been a good one. Ther e had been a flying \n",
      "motorcycle in it. He had a funny feeling he’d had the same dream \n",
      "before. \n",
      "His aunt was back outside the door. \n",
      "“Are you up yet?” she demanded. \n",
      "“Nearly,” said Harry. \n",
      "“Well, get a move on, I want yo u to look after the bacon. And \n",
      "don’t you dare let it burn, I want everything perfect on Duddy’s \n",
      "birthday.” \n",
      "Harry groaned. \n",
      "“What did you say?” his aunt snapped through the door. \n",
      "“Nothing, nothing . . .”\n",
      "\n",
      "Based only on this excerpt, provide a partial answer to the question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "If the text doesn't contain relevant information, just say \"This passage doesn't contain information about this.\"\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is an excerpt from Harry Potter:\n",
      "DIAGON  ALLEY \n",
      " 87  \n",
      "Hagrid helped Harry on to the train that would take him back \n",
      "to the Dursleys, then ha nded him an envelope. \n",
      "“Yer ticket fer Hogwarts,” he sa id. “First o’ September — King’s \n",
      "Cross — it’s all on yer ticket. Any problems with the Dursleys, \n",
      "send me a letter with yer owl, she’ll  know where to find me. . . . See \n",
      "yeh soon, Harry.” \n",
      "The train pulled out of the station. Harry wanted to watch Ha-\n",
      "grid until he was out of sight; he  rose in his seat and pressed his \n",
      "nose against the window, but he  blinked and Hagrid had gone.\n",
      "\n",
      "Based only on this excerpt, provide a partial answer to the question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "If the text doesn't contain relevant information, just say \"This passage doesn't contain information about this.\"\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is an excerpt from Harry Potter:\n",
      "sorry,” Hagrid added in a whisper to Harry, “but he’ll have a harder \n",
      "time frightenin’ you, an’ we ’ve gotta get this done.” \n",
      "So Harry set off into the heart of  the forest with Malfoy and \n",
      "Fang. They walked for nearly half an hour, deeper and deeper into \n",
      "the forest, until the path became almost impossible to follow be-\n",
      "cause the trees were so thick. Ha rry thought the bl ood seemed to \n",
      "be getting thicker. There were splashes on the roots of a tree, as \n",
      "though the poor creature had been thrashing around in pain close \n",
      "by. Harry could see a clearing ahead, through the tangled branches \n",
      "of an ancient oak. \n",
      "“Look —” he murmured, holding out his arm to stop Malfoy. \n",
      "Something bright white was gl eaming on the ground. They \n",
      "inched closer. \n",
      "It was the unicorn all right, and it was dead. Harry had never \n",
      "seen anything so beautiful and sad. Its long, slender legs were stuck\n",
      "\n",
      "Based only on this excerpt, provide a partial answer to the question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "If the text doesn't contain relevant information, just say \"This passage doesn't contain information about this.\"\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is an excerpt from Harry Potter:\n",
      "There they were. His mother and father beamed at the sight of \n",
      "him. \n",
      "“See?” Harry whispered. \n",
      "“I can’t see anything.” \n",
      "“Look! Look at them all . . . there are loads of them. . . .” \n",
      "“I can only see you.” \n",
      "“Look in it properly, go on, stand where I am.” \n",
      "Harry stepped aside, but with Ron in front of the mirror, he \n",
      "couldn’t see his family anymore, just Ron in his paisley pajamas. \n",
      "Ron, though, was staring transfixed at his image. \n",
      "“Look at me!” he said. \n",
      "“Can you see all your family standing around you?”\n",
      "\n",
      "Based only on this excerpt, provide a partial answer to the question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "If the text doesn't contain relevant information, just say \"This passage doesn't contain information about this.\"\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is an excerpt from Harry Potter:\n",
      "off — the pain in Harry’s head was building — he couldn’t see — \n",
      "he could only hear Quirrell’s terr ible shrieks and Voldemort’s yells \n",
      "of, “KILL HIM! KILL HIM!” and other voices, maybe in Harry’s \n",
      "own head, crying, “Harry! Harry!” \n",
      "He felt Quirrell’s arm wrenched  from his grasp, knew all was \n",
      "lost, and fell into blackness, down . . . down . . . down . . . \n",
      " \n",
      "Something gold was glinting just above him. The Snitch! He tried \n",
      "to catch it, but his arms were too heavy. \n",
      "He blinked. It wasn’t the Snitch at all. It was a pair of glasses. \n",
      "How strange. \n",
      "He blinked again. The smiling face of Albus Dumbledore swam \n",
      "into view above him. \n",
      "“Good afternoon, Harry,” said Dumbledore.\n",
      "\n",
      "Based only on this excerpt, provide a partial answer to the question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "If the text doesn't contain relevant information, just say \"This passage doesn't contain information about this.\"\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is an excerpt from Harry Potter:\n",
      "gall, with cold fury in her voice. Harry looked at Ron, who was still \n",
      "standing with his wand in the air.  “You’re lucky you weren’t killed. \n",
      "Why aren’t you in your dormitory?” \n",
      "Snape gave Harry a swift, pierci ng look. Harry looked at the \n",
      "floor. He wished Ron wo uld put his wand down. \n",
      "Then a small voice came out of the shadows. \n",
      "“Please, Professor McGonagall — they were looking for me.” \n",
      "“Miss Granger!” \n",
      "Hermione had managed to get to her feet at last. \n",
      "“I went looking for the troll because I — I thought I could deal \n",
      "with it on my own — you know, be cause I’ve read all about them.” \n",
      "Ron dropped his wand. Hermione Granger, telling a downright \n",
      "lie to a teacher?\n",
      "\n",
      "Based only on this excerpt, provide a partial answer to the question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "If the text doesn't contain relevant information, just say \"This passage doesn't contain information about this.\"\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is an excerpt from Harry Potter:\n",
      "The Gryffindor first years followe d Percy through the chattering \n",
      "crowds, out of the Great Hall, and up the marble staircase. Harry’s \n",
      "legs were like lead again, but only  because he was so  tired and full \n",
      "of food. He was too sleepy even to be surprised that the people in \n",
      "the portraits along the corridors whispered and pointed as they \n",
      "passed, or that twice Percy led them through doorways hidden be-\n",
      "hind sliding panels and hanging ta pestries. They climbed more\n",
      "\n",
      "Based only on this excerpt, provide a partial answer to the question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "If the text doesn't contain relevant information, just say \"This passage doesn't contain information about this.\"\n",
      "\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is an excerpt from Harry Potter:\n",
      "Potter, Voldemort’s power someho w broke — and that’s why he’s \n",
      "gone.” \n",
      "Dumbledore nodded glumly. \n",
      "“It’s — it’s true?” faltered Professor McGona gall. “After all he’s \n",
      "done . . . all the people he’s killed . . . he couldn’t kill a little boy? \n",
      "It’s just astounding . . . of all the things to stop him . . . but how in \n",
      "the name of heaven did Harry survive?” \n",
      "“We can only guess,” said Dumb ledore. “We may never know.” \n",
      "Professor McGonagall pulled out a lace handkerchief and \n",
      "dabbed at her eyes beneath her sp ectacles. Dumbledore gave a great \n",
      "sniff as he took a golden watch fr om his pocket and examined it. It \n",
      "was a very odd watch. It had twelve hands but no numbers; in-\n",
      "stead, little planets were moving around the edge. It must have\n",
      "\n",
      "Based only on this excerpt, provide a partial answer to the question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "If the text doesn't contain relevant information, just say \"This passage doesn't contain information about this.\"\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following are partial answers to a question about Harry Potter:\n",
      "This passage doesn't contain information about this.\n",
      "\n",
      "This passage doesn't contain information about this.\n",
      "\n",
      "Based on this excerpt, during Harry Potter's first year at Hogwarts, he, Malfoy, and Fang ventured deep into the Forbidden Forest where they discovered a dead unicorn. The unicorn appeared to have been injured, as there were signs of struggle and blood nearby. The scene was described as both beautiful and sad. \n",
      "\n",
      "This passage doesn't explicitly explain why the unicorn died or what caused its injuries, but it sets up a mysterious and ominous event in the forest.\n",
      "\n",
      "This passage doesn't contain information about this.\n",
      "\n",
      "This passage doesn't contain information about this.\n",
      "\n",
      "This passage doesn't contain information about this. \n",
      "\n",
      "The excerpt describes an encounter with a troll inside Hogwarts (likely from *Harry Potter and the Philosopher's Stone*), but it does not mention anything about the Forbidden Forest. The Forbidden Forest is a separate location where other events occur later in the book.\n",
      "\n",
      "This passage doesn't contain information about this.\n",
      "\n",
      "This passage doesn't contain information about this.\n",
      "\n",
      "Based on these partial answers, provide a comprehensive answer to the question: What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Final answer from map_reduce chain:\n",
      "During Harry Potter's first year at Hogwarts (*Harry Potter and the Philosopher's Stone*), he, along with Draco Malfoy and Hagrid's boarhound Fang, ventured into the Forbidden Forest as part of a detention. The group was split into two pairs: Harry and Hermione went with Hagrid, while Malfoy and Neville were paired together (though Neville was later sent back due to his fear). \n",
      "\n",
      "Deep in the forest, Harry and Hermione encountered a dead unicorn. The scene was described as both beautiful and tragic, with signs of struggle and blood nearby, indicating the unicorn had been injured. A hooded figure was seen drinking the unicorn's blood, which was later revealed to be Lord Voldemort (possessing Quirrell). Firenze, a centaur, intervened and explained that drinking unicorn blood could sustain life but at a terrible cost—cursed existence. This event foreshadowed Voldemort's weakened state and his reliance on dark means to survive.\n",
      "\n",
      "The Forbidden Forest sequence was separate from other events in the book, such as the troll encounter inside Hogwarts. The forest scene highlighted the danger and mystery of the location while advancing the plot by hinting at Voldemort's presence. \n",
      "\n",
      "In summary:  \n",
      "- Harry, Malfoy, and Fang entered the forest during detention.  \n",
      "- They discovered a dead unicorn with signs of violence.  \n",
      "- Voldemort (in Quirrell's body) was the unseen attacker, drinking the unicorn's blood.  \n",
      "- Firenze rescued Harry and provided context about the dark implications of harming a unicorn.  \n",
      "- The event deepened the mystery of Voldemort's return and the forest's role in the story.  \n",
      "\n",
      "(Note: Some responses in the original partial answers were irrelevant, such as the troll encounter, which did not occur in the forest.)\n",
      "\n",
      "Comparison with 'stuff' method:\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "During Harry Potter's first year at Hogwarts, he, Draco Malfoy, and Hagrid's dog Fang ventured into the Forbidden Forest as part of a detention. They were tasked with finding an injured unicorn. \n",
      "\n",
      "Here’s what happened:\n",
      "1. They followed a trail of unicorn blood deeper into the forest.\n",
      "2. They discovered the unicorn dead, its body gleaming white in a clearing.\n",
      "3. A hooded figure was crouched over the unicorn, drinking its blood.\n",
      "4. The figure turned on Harry, causing him intense pain in his scar.\n",
      "5. Firenze, a centaur, intervened, driving the figure away and explaining that the hooded creature was Voldemort, who was trying to regain strength by drinking unicorn blood.\n",
      "\n",
      "This event was significant because it was Harry's first direct encounter with Voldemort (though he didn’t see his face) and deepened the mystery surrounding the Dark Lord’s return.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "#### Your Task ####\n",
    "# Using langchain documentation, find out about the map reduce QA chain.  \n",
    "# answer the following questions using the chain\n",
    "#chain = load_qa_chain(llm, chain_type=\"map_reduce\")\n",
    "# answer one of the following questions of your choice. \n",
    "# query = What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\n",
    "# query = Tell me about Harry Potter and Quidditch during the first year\n",
    "\n",
    "# Choose one of the questions\n",
    "query = \"What happened in the Forbidden Forest during the first year of Harry Potter at Hogwarts?\"\n",
    "\n",
    "# Retrieve relevant documents from our ChromaDB\n",
    "relevant_docs = full_book_chroma.similarity_search(query, k=8)\n",
    "\n",
    "# Create custom prompts for map and reduce steps\n",
    "map_template = \"\"\"The following is an excerpt from Harry Potter:\n",
    "{context}\n",
    "\n",
    "Based only on this excerpt, provide a partial answer to the question: {question}\n",
    "If the text doesn't contain relevant information, just say \"This passage doesn't contain information about this.\"\n",
    "\"\"\"\n",
    "\n",
    "reduce_template = \"\"\"The following are partial answers to a question about Harry Potter:\n",
    "{summaries}\n",
    "\n",
    "Based on these partial answers, provide a comprehensive answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Create the map and reduce prompts\n",
    "map_prompt = PromptTemplate.from_template(map_template)\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)\n",
    "\n",
    "# Create the map_reduce chain\n",
    "map_reduce_chain = load_qa_chain(\n",
    "    llm,\n",
    "    chain_type=\"map_reduce\",\n",
    "    question_prompt=map_prompt,\n",
    "    combine_prompt=reduce_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Run the query through the map_reduce chain\n",
    "result = map_reduce_chain.invoke({\"input_documents\": relevant_docs, \"question\": query})\n",
    "\n",
    "print(\"\\nFinal answer from map_reduce chain:\")\n",
    "print(result[\"output_text\"])\n",
    "\n",
    "# Compare with the previously created 'stuff' method chain\n",
    "print(\"\\nComparison with 'stuff' method:\")\n",
    "stuff_result = full_book_qa_chain.invoke(query)\n",
    "print(stuff_result[\"result\"])\n",
    "\n",
    "\n",
    "# the code is generated by copilot (Claude 3.7 Sonnet Thinking), using prompt \"finish the task\". The output is not modified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a99610f",
   "metadata": {},
   "source": [
    "### 2.6 (Optional) Use DSPy with ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9714a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/lab4/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "\n",
    "lm = dspy.LM(\n",
    "    \"openai/llama-3.3-70b-instruct\",\n",
    "    api_base=os.environ[\"OPENAI_BASE_URL\"],\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"]\n",
    ")\n",
    "\n",
    "# pinecone retriever has some issues with the current version of dspy so we will use chroma retriever\n",
    "chroma_retrieve = ChromadbRM(\n",
    "    collection_name=\"harry-potter\",\n",
    "    persist_directory=\"/scratch1/chroma_db\",\n",
    "    embedding_function=baai_embedding.embed_documents,\n",
    "    k=5\n",
    ")\n",
    "\n",
    "dspy.settings.configure(\n",
    "    lm=lm,\n",
    "    rm=chroma_retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c510ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a class named GenerateAnswer which inherits from dspy.Signature\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Think and Answer questions based on the context provided.\"\"\"\n",
    "\n",
    "    # Defining input fields with descriptions\n",
    "    context = dspy.InputField(desc=\"May contain relevant facts about user query\")\n",
    "    question = dspy.InputField(desc=\"User query\")\n",
    "    \n",
    "    # Defining output field with description\n",
    "    answer = dspy.OutputField(desc=\"Answer in one or two lines\")\n",
    "\n",
    "\n",
    "# Define a class named RAG inheriting from dspy.Module\n",
    "class RAG(dspy.Module):\n",
    "    # Initialize the RAG class\n",
    "    def __init__(self):\n",
    "        # Call the superclass's constructor\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize the retrieve module\n",
    "        self.retrieve = dspy.Retrieve()\n",
    "        \n",
    "        # Initialize the generate_answer module using ChainOfThought with GenerateAnswer\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    # Define the forward method\n",
    "    def forward(self, question):\n",
    "        # Retrieve relevant context passages based on the input question\n",
    "        context = self.retrieve(question).passages\n",
    "        \n",
    "        # Generate an answer based on the retrieved context and the input question\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        \n",
    "        # Return the prediction as a dspy.Prediction object containing context and answer\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a810f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who are the robed people Mr. Dursley sees in the streets?\n",
      "\n",
      "\n",
      "Predicted Answer: The robed people are likely wizards or witches, associated with the magical world.\n",
      "\n",
      "\n",
      "Retrieved Contexts (truncated): [\"Drive, but there wasn't a map in sight. What could he have been thinking  \\nof? It must have been a trick of the light. Mr. Dursley blinked and  \\nstared at the cat. It stared back. As Mr. Dursley drove...\", 'As he had expected, Mrs. Dursley looked shocked and angry. After all,  \\nthey normally pretended she didn\\'t have a sister.  \\n \\n\"No,\" she said sharply. \"Why?\" \\n \\n\"Funny stuff on the news,\" Mr. Dursley m...', \"and it didn't improve his mood -- was the tabby cat he'd spotted that  \\nmorning. It was now sitting on his garden wall. He was sure it was the  \\nsame one; it had the same markings around  its eyes. \\n ...\"]\n"
     ]
    }
   ],
   "source": [
    "# Create a RAG (Retrieval-Augmented Generation) object\n",
    "RAG_obj = RAG()\n",
    "query = \"Who are the robed people Mr. Dursley sees in the streets?\"\n",
    "# Get the prediction from the RAG model for the given question.\n",
    "# This prediction includes both the context and the answer.\n",
    "predict_response = RAG_obj(query)\n",
    "\n",
    "# Print the question, predicted answer, and truncated retrieved contexts.\n",
    "print(f\"Question: {query}\")\n",
    "print(f\"\\n\\nPredicted Answer: {predict_response.answer}\")\n",
    "print(f\"\\n\\nRetrieved Contexts (truncated): {[c[:200] + '...' for c in predict_response.context]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7072e4fd",
   "metadata": {},
   "source": [
    "Improve the DSPy RAG class, maybe add more hops?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.dsp.utils import deduplicate\n",
    "\n",
    "# Define a class named GenerateSearchQuery which inherits from dspy.Signature\n",
    "class GenerateSearchQuery(dspy.Signature):\n",
    "    \"\"\"Write a better search query that will help answer a complex question.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    query = dspy.OutputField()\n",
    "\n",
    "class MultiHopRAG(dspy.Module):\n",
    "    def __init__(self, max_hops=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n",
    "        self.retrieve = dspy.Retrieve()\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "        self.max_hops = max_hops\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = []\n",
    "\n",
    "        for hop in range(self.max_hops):\n",
    "            query = self.generate_query[hop](context=context, question=question).query\n",
    "            passages = self.retrieve(query).passages\n",
    "            context = deduplicate(context + passages)\n",
    "\n",
    "        pred = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=pred.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f75fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Predicted Answer: The robed people Mr. Dursley sees are likely wizards or witches, possibly gathered for an event related to Harry Potter.\n"
     ]
    }
   ],
   "source": [
    "RAG_obj = MultiHopRAG()\n",
    "\n",
    "# Get the prediction from the RAG model for the given question.\n",
    "# This prediction includes both the context and the answer.\n",
    "predict_response = RAG_obj(query)\n",
    "\n",
    "# Print the question, predicted answer, and truncated retrieved contexts.\n",
    "print(f\"\\n\\nPredicted Answer: {predict_response.answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789f4d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-20T21:10:14.948483]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): May contain relevant facts about user query\n",
      "2. `question` (str): User query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `answer` (str): Answer in one or two lines\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Think and Answer questions based on the context provided.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[1] «««\n",
      "    Drive, but there wasn't a map in sight. What could he have been thinking  \n",
      "    of? It must have been a trick of the light. Mr. Dursley blinked and  \n",
      "    stared at the cat. It stared back. As Mr. Dursley drove around the  \n",
      "    corner and up the road, he watched the cat in his mirror. It was now  \n",
      "    reading the sign that said Privet Drive -- no, looking at the sign; cats \n",
      "    couldn't read maps or signs. Mr. Dursley gave himself a little shake and  \n",
      "    put the cat out of his mind. As he drove toward town he thought of  \n",
      "    nothing except a large order of drills he was hoping to get that day.  \n",
      "     \n",
      "    But on the edge of town, drills were driven out of his mind by something  \n",
      "    else. As he sat in the usual morning tr affic jam, he couldn't help \n",
      "    noticing that there seemed to be a lot of strangely dressed people\n",
      "»»»\n",
      "[2] «««\n",
      "    As he had expected, Mrs. Dursley looked shocked and angry. After all,  \n",
      "    they normally pretended she didn't have a sister.  \n",
      "     \n",
      "    \"No,\" she said sharply. \"Why?\" \n",
      "     \n",
      "    \"Funny stuff on the news,\" Mr. Dursley mumbled. \"Owls... shooting  \n",
      "    stars... and there were a lot of funny -looking people in town today...\" \n",
      "     \n",
      "    \"So?\" snapped Mrs. Dursley. \n",
      "     \n",
      "    \"Well, I just thought... maybe... it was something to do with... you  \n",
      "    know... her crowd.\" \n",
      "     \n",
      "    Mrs. Dursley sipped her tea through pursed lips. Mr. Dursley wondered  \n",
      "    whether he dared tell her he'd heard the name \"Potter.\" He decided he \n",
      "    didn't dare. Instead he said, as casually as he could, \"Their son -- \n",
      "    he'd be about Dudley's age now, wouldn't he?\"  \n",
      "     \n",
      "    \"I suppose so,\" said Mrs. Dursley stiffly.  \n",
      "     \n",
      "    \"What's his name again? Howard, isn't it?\"\n",
      "»»»\n",
      "[3] «««\n",
      "    and it didn't improve his mood -- was the tabby cat he'd spotted that  \n",
      "    morning. It was now sitting on his garden wall. He was sure it was the  \n",
      "    same one; it had the same markings around  its eyes. \n",
      "     \n",
      "    \"Shoo!\" said Mr. Dursley loudly. The cat didn't move. It just gave him a  \n",
      "    stern look. Was this normal cat behavior? Mr. Dursley wondered. Trying\n",
      "»»»\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Who are the robed people Mr. Dursley sees in the streets?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The context provided does not explicitly state who the robed people Mr. Dursley sees in the streets are. However, based on the mention of \"owls,\" \"shooting stars,\" and the overall tone of the narrative, it can be inferred that these people are likely associated with the magical world, possibly wizards or witches. The fact that Mr. Dursley connects them with \"her crowd,\" referring to his wife's sister, who is presumably involved in this magical world, further supports this inference.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "The robed people are likely wizards or witches, associated with the magical world.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-20T21:10:19.244297]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): may contain relevant facts\n",
      "2. `question` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `query` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## query ## ]]\n",
      "{query}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Write a better search query that will help answer a complex question.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "N/A\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Who are the robed people Mr. Dursley sees in the streets?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## query ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "To answer this question, we need to identify the context in which Mr. Dursley sees robed people in the streets. This scenario is likely from a work of fiction, possibly the Harry Potter series by J.K. Rowling, where Mr. Dursley is a character. The robed people could be wizards or witches, given the fantasy setting of the series. A search query should aim to specify the context of the scene, including the character and the series.\n",
      "\n",
      "[[ ## query ## ]]\n",
      "\"Mr. Dursley robed people in streets Harry Potter\"\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-20T21:10:26.950348]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): may contain relevant facts\n",
      "2. `question` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `query` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## query ## ]]\n",
      "{query}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Write a better search query that will help answer a complex question.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[1] «««\n",
      "    wearing a cloak, an emerald one. Her black hair was drawn into a tight \n",
      "    bun. She looked distinctly ruffled. \n",
      "     \n",
      "    \"How did you know it was me?\" she asked.  \n",
      "     \n",
      "    \"My dear Professor, I 've never seen a cat sit so stiffly.\"  \n",
      "     \n",
      "    \"You'd be stiff if you'd been sitting on a brick wall all day,\" said\n",
      "»»»\n",
      "[2] «««\n",
      "    nerve of him! But then it struck Mr. Dursley that this was probably some  \n",
      "    silly stunt -- these people were obviously collecting for something...  \n",
      "    yes, that would be it. The tra ffic moved on and a few minutes later, Mr.  \n",
      "    Dursley arrived in the Grunnings parking lot, his mind back on drills.  \n",
      "     \n",
      "    Mr. Dursley always sat with his back to the window in his office on the  \n",
      "    ninth floor. If he hadn't, he might have found it harder to conce ntrate \n",
      "    on drills that morning. He didn't see the owls swoop ing past in broad  \n",
      "    daylight, though people down in the street did; they pointed and gazed  \n",
      "    open- mouthed as owl after owl sped overhead. Most of them had never  \n",
      "    seen an owl even at nighttime. Mr. Dursley, however, had a perfectly\n",
      "»»»\n",
      "[3] «««\n",
      "    work, and Mrs. Dursley gossiped away happily as she wrestled a \n",
      "    screaming \n",
      "    Dudley into his high chair. \n",
      "     \n",
      "    None of them noticed a large, tawny owl flutter past the window.  \n",
      "     \n",
      "    At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs.  \n",
      "    Dursley on the cheek, and tried to kiss Dudley good -bye but missed, \n",
      "    because Dudley was now having a tantrum and throwing his cereal at the  \n",
      "    walls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He got \n",
      "    into his car and backed out of number four's drive.  \n",
      "     \n",
      "    It was on the corner of the street that he noticed the first sign of  \n",
      "    something peculiar -- a cat reading a map. For a second, Mr. Dursley  \n",
      "    didn't realize what he had seen -- then he jerked his head around to \n",
      "    look again. There was a tabby cat standing on the corner of Privet\n",
      "»»»\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Who are the robed people Mr. Dursley sees in the streets?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## query ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The question asks about the robed people Mr. Dursley sees in the streets, but the provided context does not explicitly describe such an encounter. However, it does mention Mr. Dursley's initial encounter with a person in a scene that seems unrelated to the rest of the narrative provided, and it talks about his daily routine and observations. To find out who the robed people are, we need to consider the broader context of the story, which seems to be from the Harry Potter series by J.K. Rowling. Given that the narrative mentions owls, a cat reading a map, and an unusual atmosphere, it suggests the presence of magical elements. The robed figure mentioned in the question might be related to the wizarding world, possibly wizards or witches. A better search query should aim to identify characters or scenes from the Harry Potter series that involve robed figures and Mr. Dursley.\n",
      "\n",
      "[[ ## query ## ]]\n",
      "\"Harry Potter series Mr. Dursley robed figures\" or \"Mr. Dursley encounter with wizards\"\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-20T21:10:32.756781]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): may contain relevant facts\n",
      "2. `question` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `query` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## query ## ]]\n",
      "{query}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Write a better search query that will help answer a complex question.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[1] «««\n",
      "    wearing a cloak, an emerald one. Her black hair was drawn into a tight \n",
      "    bun. She looked distinctly ruffled. \n",
      "     \n",
      "    \"How did you know it was me?\" she asked.  \n",
      "     \n",
      "    \"My dear Professor, I 've never seen a cat sit so stiffly.\"  \n",
      "     \n",
      "    \"You'd be stiff if you'd been sitting on a brick wall all day,\" said\n",
      "»»»\n",
      "[2] «««\n",
      "    nerve of him! But then it struck Mr. Dursley that this was probably some  \n",
      "    silly stunt -- these people were obviously collecting for something...  \n",
      "    yes, that would be it. The tra ffic moved on and a few minutes later, Mr.  \n",
      "    Dursley arrived in the Grunnings parking lot, his mind back on drills.  \n",
      "     \n",
      "    Mr. Dursley always sat with his back to the window in his office on the  \n",
      "    ninth floor. If he hadn't, he might have found it harder to conce ntrate \n",
      "    on drills that morning. He didn't see the owls swoop ing past in broad  \n",
      "    daylight, though people down in the street did; they pointed and gazed  \n",
      "    open- mouthed as owl after owl sped overhead. Most of them had never  \n",
      "    seen an owl even at nighttime. Mr. Dursley, however, had a perfectly\n",
      "»»»\n",
      "[3] «««\n",
      "    work, and Mrs. Dursley gossiped away happily as she wrestled a \n",
      "    screaming \n",
      "    Dudley into his high chair. \n",
      "     \n",
      "    None of them noticed a large, tawny owl flutter past the window.  \n",
      "     \n",
      "    At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs.  \n",
      "    Dursley on the cheek, and tried to kiss Dudley good -bye but missed, \n",
      "    because Dudley was now having a tantrum and throwing his cereal at the  \n",
      "    walls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He got \n",
      "    into his car and backed out of number four's drive.  \n",
      "     \n",
      "    It was on the corner of the street that he noticed the first sign of  \n",
      "    something peculiar -- a cat reading a map. For a second, Mr. Dursley  \n",
      "    didn't realize what he had seen -- then he jerked his head around to \n",
      "    look again. There was a tabby cat standing on the corner of Privet\n",
      "»»»\n",
      "[4] «««\n",
      "    to pull himself together, he let himself into the house. He was still  \n",
      "    determined not to mention anything to his wife. \n",
      "     \n",
      "    Mrs. Dursley had had a nice, normal day. She told him over dinner all  \n",
      "    about Mrs. Next Door's problems with her daughter and how Dudley had  \n",
      "    learned a new word (\"Won't!\"). Mr. Dursley tried to act normally. When  \n",
      "    Dudley had been put to bed, he went into the living room in time to  \n",
      "    catch the last report on the evening news:  \n",
      "     \n",
      "    \"And finally, bird-watchers everywhere have reported that the nation's  \n",
      "    owls have been behaving very unusually today. Although owls normally  \n",
      "    hunt at night and are hardly ever seen in daylight, there have been  \n",
      "    hundreds of sightings of these birds flying in every direction since\n",
      "»»»\n",
      "[5] «««\n",
      "    Dudley mixing with a child like that. \n",
      "     \n",
      "    When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story  \n",
      "    starts, there was nothing about the cloudy sky outside to suggest that  \n",
      "    strange and mysterious things would soon be happening all over the  \n",
      "    country. Mr. Dursley hummed as he picked out his most boring tie for\n",
      "»»»\n",
      "[6] «««\n",
      "    Mr. Dursley stopped dead. Fear flooded him. He looked back at the  \n",
      "    whisperers as if he wanted to say something to them, but thought better  \n",
      "    of it. \n",
      "     \n",
      "    He dashed back across the road, hurried up to his office, snapped at his  \n",
      "    secretary not to disturb him, seized his telephone, and had almost  \n",
      "    finished dialing his home number when he changed his mind. He put the  \n",
      "    receiver back down and stroked his mustache, thinking... no, he was  \n",
      "    being stupid. Potter wasn't such an unusual name. He was su re there were \n",
      "    lots of people called Potter who had a son called Harry. Come to think\n",
      "»»»\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Who are the robed people Mr. Dursley sees in the streets?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## query ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The question asks about the identity of the robed people Mr. Dursley sees in the streets. To find the answer, we should look for any mentions of people wearing robes in the given context. Although the context does not explicitly describe the robed individuals, it does mention strange occurrences and the presence of wizards, as indicated by the mention of owls, a cat reading a map, and the name \"Potter,\" which is likely a reference to the Harry Potter series. Given this information, it is reasonable to infer that the robed people might be wizards or individuals associated with the magical world.\n",
      "\n",
      "[[ ## query ## ]]\n",
      "\"robed figures in Harry Potter series\" or \"strange people in Harry Potter\"\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-03-20T21:10:38.767589]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): May contain relevant facts about user query\n",
      "2. `question` (str): User query\n",
      "\n",
      "Your output fields are:\n",
      "1. `reasoning` (str)\n",
      "2. `answer` (str): Answer in one or two lines\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "{answer}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Think and Answer questions based on the context provided.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[1] «««\n",
      "    wearing a cloak, an emerald one. Her black hair was drawn into a tight \n",
      "    bun. She looked distinctly ruffled. \n",
      "     \n",
      "    \"How did you know it was me?\" she asked.  \n",
      "     \n",
      "    \"My dear Professor, I 've never seen a cat sit so stiffly.\"  \n",
      "     \n",
      "    \"You'd be stiff if you'd been sitting on a brick wall all day,\" said\n",
      "»»»\n",
      "[2] «««\n",
      "    nerve of him! But then it struck Mr. Dursley that this was probably some  \n",
      "    silly stunt -- these people were obviously collecting for something...  \n",
      "    yes, that would be it. The tra ffic moved on and a few minutes later, Mr.  \n",
      "    Dursley arrived in the Grunnings parking lot, his mind back on drills.  \n",
      "     \n",
      "    Mr. Dursley always sat with his back to the window in his office on the  \n",
      "    ninth floor. If he hadn't, he might have found it harder to conce ntrate \n",
      "    on drills that morning. He didn't see the owls swoop ing past in broad  \n",
      "    daylight, though people down in the street did; they pointed and gazed  \n",
      "    open- mouthed as owl after owl sped overhead. Most of them had never  \n",
      "    seen an owl even at nighttime. Mr. Dursley, however, had a perfectly\n",
      "»»»\n",
      "[3] «««\n",
      "    work, and Mrs. Dursley gossiped away happily as she wrestled a \n",
      "    screaming \n",
      "    Dudley into his high chair. \n",
      "     \n",
      "    None of them noticed a large, tawny owl flutter past the window.  \n",
      "     \n",
      "    At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs.  \n",
      "    Dursley on the cheek, and tried to kiss Dudley good -bye but missed, \n",
      "    because Dudley was now having a tantrum and throwing his cereal at the  \n",
      "    walls. \"Little tyke,\" chortled Mr. Dursley as he left the house. He got \n",
      "    into his car and backed out of number four's drive.  \n",
      "     \n",
      "    It was on the corner of the street that he noticed the first sign of  \n",
      "    something peculiar -- a cat reading a map. For a second, Mr. Dursley  \n",
      "    didn't realize what he had seen -- then he jerked his head around to \n",
      "    look again. There was a tabby cat standing on the corner of Privet\n",
      "»»»\n",
      "[4] «««\n",
      "    to pull himself together, he let himself into the house. He was still  \n",
      "    determined not to mention anything to his wife. \n",
      "     \n",
      "    Mrs. Dursley had had a nice, normal day. She told him over dinner all  \n",
      "    about Mrs. Next Door's problems with her daughter and how Dudley had  \n",
      "    learned a new word (\"Won't!\"). Mr. Dursley tried to act normally. When  \n",
      "    Dudley had been put to bed, he went into the living room in time to  \n",
      "    catch the last report on the evening news:  \n",
      "     \n",
      "    \"And finally, bird-watchers everywhere have reported that the nation's  \n",
      "    owls have been behaving very unusually today. Although owls normally  \n",
      "    hunt at night and are hardly ever seen in daylight, there have been  \n",
      "    hundreds of sightings of these birds flying in every direction since\n",
      "»»»\n",
      "[5] «««\n",
      "    Dudley mixing with a child like that. \n",
      "     \n",
      "    When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story  \n",
      "    starts, there was nothing about the cloudy sky outside to suggest that  \n",
      "    strange and mysterious things would soon be happening all over the  \n",
      "    country. Mr. Dursley hummed as he picked out his most boring tie for\n",
      "»»»\n",
      "[6] «««\n",
      "    Mr. Dursley stopped dead. Fear flooded him. He looked back at the  \n",
      "    whisperers as if he wanted to say something to them, but thought better  \n",
      "    of it. \n",
      "     \n",
      "    He dashed back across the road, hurried up to his office, snapped at his  \n",
      "    secretary not to disturb him, seized his telephone, and had almost  \n",
      "    finished dialing his home number when he changed his mind. He put the  \n",
      "    receiver back down and stroked his mustache, thinking... no, he was  \n",
      "    being stupid. Potter wasn't such an unusual name. He was su re there were \n",
      "    lots of people called Potter who had a son called Harry. Come to think\n",
      "»»»\n",
      "[7] «««\n",
      "    They're saying he tried to kill the Potter's son, Harry. But -- he \n",
      "    couldn't. He couldn't kill that little boy. No one knows why, or how,  \n",
      "    but they're saying that when he couldn't kill Harry Potter, Voldemort's  \n",
      "    power somehow broke -- and that's why he's gone. \n",
      "     \n",
      "    Dumbledore nodded glumly. \n",
      "     \n",
      "    \"It's -- it's true?\" faltered Professor McGonagall. \"After all he's  \n",
      "    done... all the people he's killed... he couldn't kill a little boy?  \n",
      "    It's just astounding... of all the things to stop him... but how in the  \n",
      "    name of heaven did Harry survive?\" \n",
      "     \n",
      "    \"We can only guess,\" said Dumbledore. \"We may never know.\"  \n",
      "     \n",
      "    Professor McGonagall pulled out a lace handkerchief and dabbed at her  \n",
      "    eyes beneath her spectacles. Dumbledore gave a great sniff as he took a\n",
      "»»»\n",
      "\n",
      "[[ ## question ## ]]\n",
      "Who are the robed people Mr. Dursley sees in the streets?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## answer ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The context does not explicitly describe the robed people Mr. Dursley sees in the streets, but based on the narrative, it can be inferred that these individuals are likely wizards or witches, possibly connected to the wizarding world that is being introduced in the story. The mention of owls flying during the day, a cat reading a map, and the overall strange occurrences suggest that something unusual and magical is happening. Given the setting and the events unfolding, it's reasonable to deduce that the robed figures are part of this mystical or magical community, possibly gathered for a significant event related to Harry Potter.\n",
      "\n",
      "[[ ## answer ## ]]\n",
      "The robed people Mr. Dursley sees are likely wizards or witches, possibly gathered for an event related to Harry Potter.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d0d396",
   "metadata": {},
   "source": [
    "### 2.7 (Optional) Using Pinecone, an online vector DB \n",
    "\n",
    "You have many reasons to store your DB online in a SaaS / PaaS service.  For example, \n",
    "- you want to scale the queries to many concurrent users\n",
    "- you want more data reliability without having to worry about DB management\n",
    "- you want to share the DB but without owning any servers\n",
    "\n",
    "If you want to store your embeddings online, try pinecone with the code below. You must go to [Pinecone.io](https://www.pinecone.io/) and set up an account. Then you need to generate an api-key and create an \"index\", this can be done by navigating through the homepage once you've logged in to Pinecone, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c7ebca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You might need the following code to access OpenAI API or SerpAPI.\n",
    "# os.environ['HTTP_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "# os.environ['HTTPS_PROXY']=\"http://Clash:QOAF8Rmd@10.1.0.213:7890\"\n",
    "# os.environ['ALL_PROXY']=\"socks5://Clash:QOAF8Rmd@10.1.0.213:7893\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b75f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "PINECONE_API_KEY = os.environ['PINECONE_API_KEY']\n",
    "PINECONE_INDEX_NAME = os.environ['PINECONE_INDEX_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"lab4\"\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "existing_indexes = [index_info[\"name\"] for index_info in pc.list_indexes()]\n",
    "if index_name in existing_indexes:\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1024,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    ")\n",
    "    \n",
    "docsearch_pinecone = PineconeVectorStore.from_texts(\n",
    "    [t.page_content for t in texts], baai_embedding, index_name=index_name, namespace=\"harry-potter\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 0 results. \n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Who might \"You-Know-Who\" be? Why isn\\'t this person referred to by a given name?',\n",
       " 'result': '\"You-Know-Who\" is a phrase used in the Harry Potter series by J.K. Rowling to refer to the dark wizard Lord Voldemort. Characters in the series often avoid saying his name directly due to fear and superstition. This practice stems from a combination of cultural taboos and the belief that saying his name might attract his attention or invoke his presence. The reluctance to use his name is also a reflection of the widespread terror he instilled in the wizarding community. Harry Potter and a few others, like Albus Dumbledore, are notable exceptions who use Voldemort\\'s name openly, symbolizing their refusal to be intimidated by him.'}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=CHAT_MODEL)\n",
    "query = '''Who might \"You-Know-Who\" be? Why isn't this person referred to by a given name?'''\n",
    "\n",
    "print_search_results(docsearch_pinecone.similarity_search(query))\n",
    "chain = RetrievalQA.from_chain_type(\n",
    "    llm, chain_type=\"stuff\", verbose=True, retriever=docsearch_pinecone.as_retriever(k=5)\n",
    ")\n",
    "chain.invoke(query)\n",
    "\n",
    "# we can use the full-book to test 'map-reduce', try it !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7453fd84-ba39-4f2b-ab23-23b94d45d727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search returned 0 results. \n"
     ]
    }
   ],
   "source": [
    "# query with pinecone\n",
    "docs = docsearch_pinecone.similarity_search(query)\n",
    "print_search_results(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1053e7a-3c56-44d2-9d87-1b08f624dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Your Task ####\n",
    "# modify the QA chain in Section 2.5 (Chapter 1 only) to use pinecone instead of ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08cc6131-6a1a-40f5-8af0-afc5c723e49e",
   "metadata": {},
   "source": [
    "### 2.7 (Optional) Use multiple vector stores in Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1053e7a-3c56-44d2-9d87-1b08f624dc53",
   "metadata": {},
   "source": [
    "In this section, we are going to create a simple QA agent that can decide by itself which of the two vectorstores it should switch to for questions of differnent fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b4118-4e34-4d3d-8230-a13bf77daa59",
   "metadata": {},
   "source": [
    "#### Preparing the tools for the agent.\n",
    "\n",
    "We will use our chroma_based Harry Potter vectorDB, and let's create another one containing President Biden's State of the Union speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949662aa-5044-4899-ba50-5e06ac7df371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '/ssdshare/share/lab4/state_of_the_union.txt'}, page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.'), Document(metadata={'source': '/ssdshare/share/lab4/state_of_the_union.txt'}, page_content='Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "documents = TextLoader('/ssdshare/share/lab4/state_of_the_union.txt').load()\n",
    "texts = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0).split_documents(documents)\n",
    "docsearch3 = Chroma.from_documents(texts, \n",
    "                                   baai_embedding, \n",
    "                                   collection_name=\"state-of-union\", \n",
    "                                   persist_directory=\"/scratch1/chroma_db\")\n",
    "print(texts[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b4118-4e34-4d3d-8230-a13bf77daa59",
   "metadata": {},
   "source": [
    "To allow the agent query these databases, we need to define two RetrievalQA chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd41e19-fcff-4358-9374-2b36b29d1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=CHAT_MODEL)\n",
    "\n",
    "harry_potter = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                           chain_type=\"stuff\", \n",
    "                                           retriever=docsearch_chroma_reloaded.as_retriever(\n",
    "                                                  search_kwargs={\"k\": 8}\n",
    "                                           ))\n",
    "state_of_union = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                             chain_type=\"stuff\", \n",
    "                                             retriever=docsearch3.as_retriever(\n",
    "                                                    search_kwargs={\"k\": 8}\n",
    "                                             ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe451ef-4137-4b86-9254-4117c6802b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"<class 'dict'>:\"\n",
      "{'query': 'Why does McGonagall seem concerned about Harry being raised by the '\n",
      "          'Dursleys?',\n",
      " 'result': 'Professor McGonagall is concerned about Harry being raised by the '\n",
      "           'Dursleys because she has observed their behavior and knows they '\n",
      "           'are not kind or nurturing people. She mentions that they are \"the '\n",
      "           'worst sort of Muggles imaginable\" and expresses doubt that they '\n",
      "           'will provide a loving and supportive environment for Harry. Her '\n",
      "           'concern stems from her understanding that Harry, as a young child '\n",
      "           'who has just lost his parents, will need care and compassion, '\n",
      "           'which she fears the Dursleys are incapable of providing.'}\n",
      "\"<class 'dict'>:\"\n",
      "{'query': 'What did the president say about justice Breyer?',\n",
      " 'result': 'The President honored Justice Stephen Breyer, describing him as an '\n",
      "           'Army veteran, Constitutional scholar, and retiring Justice of the '\n",
      "           'United States Supreme Court. He expressed gratitude for Justice '\n",
      "           'Breyer\\'s service, stating, \"Justice Breyer, thank you for your '\n",
      "           'service.\" Additionally, the President mentioned that one of his '\n",
      "           'most serious constitutional responsibilities is nominating someone '\n",
      "           'to serve on the Supreme Court, and he highlighted his recent '\n",
      "           'nomination of Circuit Court of Appeals Judge Ketanji Brown Jackson '\n",
      "           \"to continue Justice Breyer's legacy of excellence.\"}\n"
     ]
    }
   ],
   "source": [
    "# Now try both chains\n",
    "\n",
    "print_with_type(harry_potter.invoke('Why does McGonagall seem concerned about Harry being raised by the Dursleys?'))\n",
    "print_with_type(state_of_union.invoke(\"What did the president say about justice Breyer?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73957e1e-f3e2-48e6-91db-d669d5cbe3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, Tool\n",
    "\n",
    "# define tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"State of Union QA System\",\n",
    "        func=state_of_union.run,\n",
    "        description=\"useful for when you need to answer questions about the most recent state of the union address. Input should be a fully formed question.\",\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"Harry Potter QA System\",\n",
    "        func=harry_potter.run,\n",
    "        description=\"useful for when you need to answer questions about Harry Potter. Input should be a fully formed question.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe451ef-4137-4b86-9254-4117c6802b6a",
   "metadata": {},
   "source": [
    "Now we can create the Agent giving both chains as tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b068ff-d822-44ec-ba63-c47f49b492e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=CHAT_MODEL,\n",
    ")\n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    prompt=prompt,\n",
    ")\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "    agent=agent, tools=tools, verbose=True, memory=ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85245e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThe question is about a statement made by the president, specifically regarding Justice Breyer. This is likely related to the most recent State of the Union address.  \n",
      "Action: State of Union QA System  \n",
      "Action Input: What did the president say about Justice Breyer?  \n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mThe President honored Justice Stephen Breyer, describing him as an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. He thanked Justice Breyer for his dedicated service to the country. Additionally, the President mentioned that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to continue Justice Breyer’s legacy of excellence on the Supreme Court.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: The President honored Justice Stephen Breyer, describing him as an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. He thanked Justice Breyer for his dedicated service to the country and mentioned that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to continue Justice Breyer’s legacy of excellence on the Supreme Court.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What did the president say about justice Breyer?',\n",
       " 'chat_history': [HumanMessage(content='What did the president say about justice Breyer?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The President honored Justice Stephen Breyer, describing him as an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. He thanked Justice Breyer for his dedicated service to the country and mentioned that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to continue Justice Breyer’s legacy of excellence on the Supreme Court.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The President honored Justice Stephen Breyer, describing him as an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. He thanked Justice Breyer for his dedicated service to the country and mentioned that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to continue Justice Breyer’s legacy of excellence on the Supreme Court.'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you find the agent is stuck, you can try other more powerful model, like DeepSeek\n",
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What did the president say about justice Breyer?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497fde49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThis question is about Harry Potter, so I should use the Harry Potter QA System to find the answer.  \n",
      "Action: Harry Potter QA System  \n",
      "Action Input: Why does McGonagall seem concerned about Harry being raised by the Dursleys?  \n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mProfessor McGonagall seems concerned about Harry being raised by the Dursleys because she has observed their behavior and finds them to be neglectful and unkind. She mentions that they are \"the worst sort of Muggles\" and expresses doubt that they will provide Harry with a loving and nurturing environment. Her concern is rooted in her understanding of the Dursleys' character and her desire for Harry to grow up in a supportive and caring home, especially after the tragic loss of his parents.\u001b[0m\u001b[32;1m\u001b[1;3mI now know the final answer.  \n",
      "Final Answer: Professor McGonagall is concerned about Harry being raised by the Dursleys because she has observed their neglectful and unkind behavior, describing them as \"the worst sort of Muggles.\" She doubts they will provide Harry with a loving and nurturing environment, which is especially important given the tragic loss of his parents.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Why does McGonagall seem concerned about Harry being raised by the Dursleys?',\n",
       " 'chat_history': [HumanMessage(content='What did the president say about justice Breyer?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The President honored Justice Stephen Breyer, describing him as an Army veteran, Constitutional scholar, and retiring Justice of the United States Supreme Court. He thanked Justice Breyer for his dedicated service to the country and mentioned that he nominated Circuit Court of Appeals Judge Ketanji Brown Jackson to continue Justice Breyer’s legacy of excellence on the Supreme Court.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Why does McGonagall seem concerned about Harry being raised by the Dursleys?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Professor McGonagall is concerned about Harry being raised by the Dursleys because she has observed their neglectful and unkind behavior, describing them as \"the worst sort of Muggles.\" She doubts they will provide Harry with a loving and nurturing environment, which is especially important given the tragic loss of his parents.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Professor McGonagall is concerned about Harry being raised by the Dursleys because she has observed their neglectful and unkind behavior, describing them as \"the worst sort of Muggles.\" She doubts they will provide Harry with a loving and nurturing environment, which is especially important given the tragic loss of his parents.'}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"Why does McGonagall seem concerned about Harry being raised by the Dursleys?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85245e2",
   "metadata": {},
   "source": [
    "We can see that the agent can \"smartly\" choose which QA system to use given a specific question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fde49",
   "metadata": {},
   "source": [
    "## 3 Your Task: putting it all together: Langchain with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e6d104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 2 65536 (offset 0)\n",
      "Ignoring wrong pointing object 8 65536 (offset 0)\n",
      "Ignoring wrong pointing object 13 65536 (offset 0)\n",
      "Ignoring wrong pointing object 18 65536 (offset 0)\n",
      "Ignoring wrong pointing object 23 65536 (offset 0)\n",
      "Ignoring wrong pointing object 28 65536 (offset 0)\n",
      "Ignoring wrong pointing object 33 65536 (offset 0)\n",
      "Ignoring wrong pointing object 38 65536 (offset 0)\n",
      "Ignoring wrong pointing object 43 65536 (offset 0)\n",
      "Ignoring wrong pointing object 48 65536 (offset 0)\n",
      "Ignoring wrong pointing object 53 65536 (offset 0)\n",
      "Ignoring wrong pointing object 58 65536 (offset 0)\n",
      "Ignoring wrong pointing object 63 65536 (offset 0)\n",
      "Ignoring wrong pointing object 68 65536 (offset 0)\n",
      "Ignoring wrong pointing object 73 65536 (offset 0)\n",
      "Ignoring wrong pointing object 78 65536 (offset 0)\n",
      "Ignoring wrong pointing object 83 65536 (offset 0)\n",
      "Ignoring wrong pointing object 88 65536 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding chunks 0 to 49\n",
      "Adding chunks 50 to 99\n",
      "Adding chunks 100 to 149\n",
      "Adding chunks 150 to 199\n",
      "Adding chunks 200 to 249\n",
      "Adding chunks 250 to 299\n",
      "Adding chunks 300 to 349\n",
      "Adding chunks 350 to 399\n",
      "Adding chunks 400 to 449\n",
      "Adding chunks 450 to 499\n",
      "Adding chunks 500 to 549\n",
      "Adding chunks 550 to 599\n",
      "Adding chunks 600 to 649\n",
      "Adding chunks 650 to 699\n",
      "Adding chunks 700 to 749\n",
      "Adding chunks 750 to 799\n",
      "Adding chunks 800 to 849\n",
      "Adding chunks 850 to 899\n",
      "Adding chunks 900 to 949\n",
      "Adding chunks 950 to 999\n",
      "Adding chunks 1000 to 1049\n",
      "Adding chunks 1050 to 1099\n",
      "Adding chunks 1100 to 1149\n",
      "Adding chunks 1150 to 1199\n",
      "Adding chunks 1200 to 1249\n",
      "Adding chunks 1250 to 1299\n",
      "Adding chunks 1300 to 1349\n",
      "Adding chunks 1350 to 1399\n",
      "Adding chunks 1400 to 1428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_172215/2169632219.py:67: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n",
      "/tmp/ipykernel_172215/2169632219.py:103: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"question\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Demonstrating conversational capability:\n",
      "\n",
      "Question 1: What is quantum gravity and why is it important?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful AI assistant that answers questions about research papers on quantum gravity and philosophy of science.\n",
      "Use the following pieces of context to answer the question at the end. \n",
      "If you don't know the answer, just say you don't know. Don't make up an answer.\n",
      "Keep your answer brief and concise - no more than 100 words.\n",
      "\n",
      "Context: The starting point in the covariant approach is a Lagrangian for gravity (with\n",
      "matter or without, giving pure gravity). The Einstein-Hilbert Lagrangian is:\n",
      "\n",
      "care of the various problems cases facing Popper’s more stringent methodological\n",
      "model. However, the central principle guiding the construction of quantum gravity\n",
      "directed research programmes are precisely mathematical consistency and the ab-\n",
      "sence of anomalies (and the ability to be consistent with known, already observed\n",
      "data). Moreover, the empirical detachment of quantum gravity research means that\n",
      "the leniency that Lakatos’ methodology allows for (namely, when there is empir-\n",
      "\n",
      "tral concepts and laws of the programme), in the case of quantum gravity. And\n",
      "there are examples in which the modiﬁcations made to rescue a quantum gravity\n",
      "programme from inconsistency and anomaly are not “blatantly ad hoc” (to use a\n",
      "phrase of Cushing’s— [15], p. 78). In other words, we can ﬁnd cases where the ad-\n",
      "dition of an auxiliary assumption to solve one problem (and so, a blatantly ad hoc\n",
      "move) has uses beyond the reason it was initially introduced. The most obvious\n",
      "\n",
      "quantum gravity be stopped merely because it must employ a second-best \n",
      "method. What I would have of the physics community is a more honest \n",
      "appraisal of the standing of its efforts in this area in light of the deficiencies \n",
      "of the method that will of necessity be employed. One of the current the- \n",
      "ories of quantum gravity may indeed turn out to be supported by as of \n",
      "now undreamt of direct experimental confirmation, may turn out to be\n",
      "\n",
      "boundary to the wavelengths of quantum ﬁelds. See §4 for more on these two approaches.\n",
      "23The characteristic ‘Planck length’ is computed by dimensional analysis by combining the con-\n",
      "stants that would control the theory of quantum gravity into a unique length. As shown above, this\n",
      "is lp =\n",
      "√\n",
      "ℏG/c3 = 1 .6 ×10−33cm: a minuscule value, making gravity (effectively) a ‘collec-\n",
      "tive phenomenon’ requiring lots of interacting masses. That quantum gravitational effects will not be\n",
      "\n",
      "gravity do not stop there: quantum gravity research is important too in our primary\n",
      "theories; namely, the standard model of particle physics and classical general rel-\n",
      "ativity (both of which inform the standard model of cosmology). These theories\n",
      "would look very different were it not for the impact of quantum gravity research\n",
      "and the concepts and tools it has generated—indeed, this external utility has been\n",
      "adopted at various times to support continued research on quantum gravity.\n",
      "\n",
      "Question: What is quantum gravity and why is it important?\n",
      "\n",
      "Your answer (maximum 100 words):\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: Quantum gravity is a theoretical framework aiming to unify general relativity and quantum mechanics, addressing inconsistencies between them. It is important because it seeks to resolve fundamental questions about spacetime at the Planck scale (~10⁻³³ cm), where quantum effects dominate gravity. Additionally, quantum gravity research has influenced other theories like the standard model of particle physics and cosmology, providing tools and concepts that shape our understanding of physics. Despite limited direct experimental evidence, its mathematical consistency and potential to explain unresolved phenomena (e.g., black holes, the Big Bang) drive its significance.\n",
      "Sources:\n",
      "  Source 1: Rickles. QGMeets&HPS.pdf - Page 24\n",
      "  Source 2: Rickles. QGMeets&HPS.pdf - Page 28\n",
      "\n",
      "Question 2: How did Einstein contribute to this field?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: What is quantum gravity and why is it important?\n",
      "Assistant: Quantum gravity is a theoretical framework aiming to unify general relativity and quantum mechanics, addressing inconsistencies between them. It is important because it seeks to resolve fundamental questions about spacetime at the Planck scale (~10⁻³³ cm), where quantum effects dominate gravity. Additionally, quantum gravity research has influenced other theories like the standard model of particle physics and cosmology, providing tools and concepts that shape our understanding of physics. Despite limited direct experimental evidence, its mathematical consistency and potential to explain unresolved phenomena (e.g., black holes, the Big Bang) drive its significance.\n",
      "Follow Up Input: How did Einstein contribute to this field?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful AI assistant that answers questions about research papers on quantum gravity and philosophy of science.\n",
      "Use the following pieces of context to answer the question at the end. \n",
      "If you don't know the answer, just say you don't know. Don't make up an answer.\n",
      "Keep your answer brief and concise - no more than 100 words.\n",
      "\n",
      "Context: The starting point in the covariant approach is a Lagrangian for gravity (with\n",
      "matter or without, giving pure gravity). The Einstein-Hilbert Lagrangian is:\n",
      "\n",
      "quantum electrodynamics is an inherently incomplete theory. It ignores many processes\n",
      "that come into play at high energies or short distances. In particular, it completely ignores\n",
      "the microstructure of space-time and simply assumes that space-time can be approximated\n",
      "by a smooth continuum even below the Planck scale. Therefore, it can plead incompleteness\n",
      "and shift the burden of this inﬁnity to a more complete theory. A ‘theory of everything’ on\n",
      "\n",
      "this sense, no theory of quantum gravity has the slightest bit more of \n",
      "scientific merit than any other, no matter the elegance of the theory, no \n",
      "matter the number or eminence of the physicists working on the theory. \n",
      "5. A Plea for Modesty. Most of the researchers at work in quantum gravity \n",
      "today are conscientious and scrupulous scientists. The immodest and gran- \n",
      "diose claims made by a few, however, about the achievements, indeed the\n",
      "\n",
      "It may come as a surprise that the necessity of a quantum theory of gravity was pointed\n",
      "out by Einstein already in 1916 —barely a year after the discovery of general relativity. In\n",
      "a paper in the Preussische Akademie Sitzungsberichte, he wrote:\n",
      "“Nevertheless, due to the inneratomic movement of electrons, atoms would have\n",
      "to radiate not only electromagnetic but also gravitational energy, if only in tiny\n",
      "amounts. As this is hardly true in Nature, it appears that quantum theory would\n",
      "\n",
      "Above all, it creates the certitude of being right [prematurely].\n",
      "ACKNOWLEDGEMENTS:\n",
      "My understanding of quantum gravity has deepened through discussions with a large\n",
      "number of colleagues. Among them, I would especially like to thank John Baez, Peter\n",
      "Bergmann, Martin Bojowald, Alex Corichi, Klaus Fredenhagen, Rodolfo Gambini, Jim Har-\n",
      "tle, Gary Horowitz, Ted Jacobson, Kirill Krasnov, Jerzy Lewandowski, Don Marolf, Jose\n",
      "\n",
      "relativity for “physics students ... who know about quantum theory and mesons and\n",
      "the fundamental particles, which were unknown in Einstein’s day” (Feynman’s\n",
      "Lectures on Gravitation ; cited in [59], p. 329). We have seen that the particle\n",
      "physicist’s approach is conceptually very different from Einstein’s own geometri-\n",
      "cal approach. Feynman, though not the ﬁrst to write general relativity in this way,\n",
      "sought to tailor the presentation of the theory to the needs of his students. 56 The\n",
      "\n",
      "Question: **Standalone question:**  \n",
      "*How did Einstein contribute to the field of quantum gravity?*  \n",
      "\n",
      "(Alternatively, for slightly broader context: *What was Einstein's role in the development of quantum gravity?*)\n",
      "\n",
      "Your answer (maximum 100 words):\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: Einstein contributed to quantum gravity by recognizing its necessity early. In 1916, just a year after formulating general relativity, he noted in a paper that atoms would radiate gravitational energy due to quantum effects—a phenomenon not observed in nature. This implied quantum theory must modify gravity, marking one of the first hints of quantum gravity. However, he did not develop a full theory. His insights laid groundwork, but later approaches (e.g., Feynman's particle-physics view) diverged from his geometric perspective. Einstein's role was thus foundational but incomplete. (Word count: 100)\n",
      "Sources:\n",
      "  Source 1: Rickles. QGMeets&HPS.pdf - Page 24\n",
      "  Source 2: Ashtekar. WindingRoadToQG.pdf - Page 7\n",
      "\n",
      "Question 3: What philosophical challenges does quantum gravity present?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: What is quantum gravity and why is it important?\n",
      "Assistant: Quantum gravity is a theoretical framework aiming to unify general relativity and quantum mechanics, addressing inconsistencies between them. It is important because it seeks to resolve fundamental questions about spacetime at the Planck scale (~10⁻³³ cm), where quantum effects dominate gravity. Additionally, quantum gravity research has influenced other theories like the standard model of particle physics and cosmology, providing tools and concepts that shape our understanding of physics. Despite limited direct experimental evidence, its mathematical consistency and potential to explain unresolved phenomena (e.g., black holes, the Big Bang) drive its significance.\n",
      "Human: How did Einstein contribute to this field?\n",
      "Assistant: Einstein contributed to quantum gravity by recognizing its necessity early. In 1916, just a year after formulating general relativity, he noted in a paper that atoms would radiate gravitational energy due to quantum effects—a phenomenon not observed in nature. This implied quantum theory must modify gravity, marking one of the first hints of quantum gravity. However, he did not develop a full theory. His insights laid groundwork, but later approaches (e.g., Feynman's particle-physics view) diverged from his geometric perspective. Einstein's role was thus foundational but incomplete. (Word count: 100)\n",
      "Follow Up Input: What philosophical challenges does quantum gravity present?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful AI assistant that answers questions about research papers on quantum gravity and philosophy of science.\n",
      "Use the following pieces of context to answer the question at the end. \n",
      "If you don't know the answer, just say you don't know. Don't make up an answer.\n",
      "Keep your answer brief and concise - no more than 100 words.\n",
      "\n",
      "Context: quency data; incidents and histories; and generally known rules and \n",
      " statuses. He argues that the most effective methods for collecting \n",
      " these three types of information are, respectively, sample surveys, \n",
      " participant observation, and interviewing informants. Most of the \n",
      " information with which we are concerned in this exploratory study \n",
      " is comparable to Zelditch's category of 'generally known rules and \n",
      " statuses.' In other words, this category consists of institutionalized\n",
      "\n",
      "suggests. Nickles (1987) has referred to a similar concept as genera- \n",
      "tive potential, the ability to generate new problems and areas of \n",
      "further research. It is U-fertility, or generative potential, which is \n",
      "important during the developmental phases of a theory. If researchers \n",
      "do not perceive this promise in a theory, they may never pursue it. \n",
      "The relevance of P-fertility will not arise. This Haas-Bohr example \n",
      "illustrates two theories with greatly different U-fertilities. Such fertility\n",
      "\n",
      "physical theory and its logical development do not always proceed side by side, and logically, the\n",
      "particle physicist has no strong a priori reason for treating gravity as a special case” ([32], p. 79).\n",
      "\n",
      "best theories are presumably both elegant and true, and the worst \n",
      " are neither. \n",
      " Some theorists place elegance above testability. One informant \n",
      " said: 'Theoretical physicists want the best approach - one that is \n",
      " aesthetic, not one that fits the data. They will make it fit the data \n",
      " later. Phenomenologists want a model that fits the data.' Another \n",
      " informant, also a theorist, expressed the opposite point of view. \n",
      " 'Unless precise predictions are possible and the rules of calculation\n",
      "\n",
      "In this article, one finds no doubts about the possibility of con­\n",
      "structing a cosmological theory based solely on general relativity. In \n",
      "Bronsteyn’s subsequent papers concerning cosmology, such doubts are \n",
      "characteristic, and they are based on his general conception of physics. \n",
      "Bronsteyn looked at physics through the “magic cGh cube.” He drew \n",
      "a chart describing the structure of theoretical physics based on the role\n",
      "\n",
      "extended case summary, may be of most use in attempting to decide \n",
      "how theories are appraised. I do, however, conclude with one longer \n",
      "summary of a specific episode in theoretical nuclear physics. \n",
      "Let me begin by summarizing an earlier attempt (Cushing 1982) to \n",
      "compare and contrast Kuhn's and Lakatos's models of science by \n",
      "studying developments in the modern theoretical physics of this cen- \n",
      "tury. This was an historical outline not subscribing to either\n",
      "\n",
      "Question: **\"What philosophical challenges does quantum gravity present?\"**  \n",
      "\n",
      "(Note: The original question is already standalone, so no rephrasing is needed. It directly asks about philosophical issues without relying on prior context.)\n",
      "\n",
      "Your answer (maximum 100 words):\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: Quantum gravity presents several philosophical challenges:  \n",
      "\n",
      "1. **Theory Appraisal**: Balancing elegance (e.g., mathematical beauty) against empirical testability, as theorists often prioritize aesthetics over immediate data fit.  \n",
      "2. **Generative Potential (U-fertility)**: A theory’s ability to inspire new research is crucial, but quantum gravity’s developmental phase raises questions about its long-term promise.  \n",
      "3. **Unification vs. Specialization**: Gravity’s unique role in physics (e.g., Bronsteyn’s \"cGh cube\") challenges whether it should be treated as a special case or unified with other forces.  \n",
      "4. **Methodological Divergence**: Conflicting approaches (e.g., particle physics vs. phenomenology) highlight tensions in theory construction and validation.  \n",
      "\n",
      "(Word count: 100)\n",
      "Sources:\n",
      "  Source 1: Crane-ExploratoryStudyKuhnian-1980.pdf - Page 3\n",
      "  Source 2: Cushin. Jstfy&SelectOfSciThry.pdf - Page 9\n",
      "\n",
      "Question 4: How does Kuhn's theory of scientific revolutions relate to quantum gravity research?\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: What is quantum gravity and why is it important?\n",
      "Assistant: Quantum gravity is a theoretical framework aiming to unify general relativity and quantum mechanics, addressing inconsistencies between them. It is important because it seeks to resolve fundamental questions about spacetime at the Planck scale (~10⁻³³ cm), where quantum effects dominate gravity. Additionally, quantum gravity research has influenced other theories like the standard model of particle physics and cosmology, providing tools and concepts that shape our understanding of physics. Despite limited direct experimental evidence, its mathematical consistency and potential to explain unresolved phenomena (e.g., black holes, the Big Bang) drive its significance.\n",
      "Human: How did Einstein contribute to this field?\n",
      "Assistant: Einstein contributed to quantum gravity by recognizing its necessity early. In 1916, just a year after formulating general relativity, he noted in a paper that atoms would radiate gravitational energy due to quantum effects—a phenomenon not observed in nature. This implied quantum theory must modify gravity, marking one of the first hints of quantum gravity. However, he did not develop a full theory. His insights laid groundwork, but later approaches (e.g., Feynman's particle-physics view) diverged from his geometric perspective. Einstein's role was thus foundational but incomplete. (Word count: 100)\n",
      "Human: What philosophical challenges does quantum gravity present?\n",
      "Assistant: Quantum gravity presents several philosophical challenges:  \n",
      "\n",
      "1. **Theory Appraisal**: Balancing elegance (e.g., mathematical beauty) against empirical testability, as theorists often prioritize aesthetics over immediate data fit.  \n",
      "2. **Generative Potential (U-fertility)**: A theory’s ability to inspire new research is crucial, but quantum gravity’s developmental phase raises questions about its long-term promise.  \n",
      "3. **Unification vs. Specialization**: Gravity’s unique role in physics (e.g., Bronsteyn’s \"cGh cube\") challenges whether it should be treated as a special case or unified with other forces.  \n",
      "4. **Methodological Divergence**: Conflicting approaches (e.g., particle physics vs. phenomenology) highlight tensions in theory construction and validation.  \n",
      "\n",
      "(Word count: 100)\n",
      "Follow Up Input: How does Kuhn's theory of scientific revolutions relate to quantum gravity research?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful AI assistant that answers questions about research papers on quantum gravity and philosophy of science.\n",
      "Use the following pieces of context to answer the question at the end. \n",
      "If you don't know the answer, just say you don't know. Don't make up an answer.\n",
      "Keep your answer brief and concise - no more than 100 words.\n",
      "\n",
      "Context: Scientific revolutions are thereby called \"those non-cummulative developmen- \n",
      "tal episodes in which an older paradigm is replaced in whole or in part by in \n",
      "imcompatible one\" (p. 92). Extraordinary science as opposed to normal science \n",
      "appears when normal science is faced with a crisis. \n",
      "For further use we have to describe in more detail the two basic concepts \n",
      "\"anomaly\" and \"crisis\" which play a central role in Kuhn's scheme:\n",
      "\n",
      "In principle, one could construct an infinite number of 'gauge' \n",
      " models, and a considerable number have been proposed. Many \n",
      " have had very brief lives.22 A substantial amount of consensus has \n",
      " now been reached on the Weinberg-Salam model. Much of it has \n",
      " been verified with great precision, although an important predic- \n",
      " tion of the theory remains to be verified. \n",
      " To summarize, informants' descriptions of theoretical high \n",
      " energy physics indicate that the various elements of the Kuhnian\n",
      "\n",
      "Crane: Kuhnian Paradigms 37 \n",
      " It is clear that this specialty did not consistently behave as one \n",
      " would expect on the basis of Kuhn's discussion. Throughout the \n",
      " period covered by this study, the fundamental principles of the \n",
      " field were not challenged. Therefore, the field was not in a state of \n",
      " 'crisis' or 'revolution'. However, successful exemplars were present \n",
      " in some periods and in some areas, but not in others. \n",
      " Types of Exemplars\n",
      "\n",
      "the paradigm. Changes in exemplars alone do not correspond to a \n",
      " revolution. Kuhn indicates that a paradigm is only rejected when a \n",
      " superior one is available to replace it. An important aspect of this \n",
      " sort of change is the perception of 'anomalies' in the existing \n",
      " paradigm - that is to say, scientific events that are not predicted or \n",
      " explained by the paradigm. \n",
      " Does anything correspond in this field to the process of anomaly,\n",
      "\n",
      "to deal with the realities of quantum gravity. 54 Firstly he sets up the problem of\n",
      "quantum gravity as one involving a pair of “incompatible paradigms”, i.e. rather\n",
      "than merely incommensurable paradigms which Kuhn allows. Moreover, argues\n",
      "Audretsch, both of these paradigms involve an “all claim”.\n",
      "I think this exposes an error in Audretsch’s formulation of the problem for\n",
      "Kuhn, for neither general relativity nor quantum theory have an all-claim built\n",
      "\n",
      "Crane: Kuhnian Paradigms 3 1 \n",
      " represent a group or community whose members share beliefs \n",
      " representing all of the elements of a paradigm. Therefore, the first \n",
      " questions to examine are: (1) Are these elements present? and \n",
      " (2) Are these elements always present in conjunction with one \n",
      " another? \n",
      " Symbolic Generalizations \n",
      " According to informants' reports, relativistic quantum mechanics \n",
      " appears to play the role of symbolic generalizations for the entire\n",
      "\n",
      "Question: **How does Kuhn's theory of scientific revolutions apply to or intersect with quantum gravity research?**  \n",
      "\n",
      "(Alternatively, for brevity: **How does Kuhn's theory of scientific revolutions relate to quantum gravity?**)\n",
      "\n",
      "Your answer (maximum 100 words):\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Answer: Kuhn's theory of scientific revolutions intersects with quantum gravity research in debates over whether it involves \"incompatible paradigms\" (general relativity and quantum theory) or merely incommensurable ones. Audretsch argues quantum gravity presents a unique case of two paradigms with \"all-claims,\" but critics note neither theory fully claims universality. Crane's analysis suggests quantum gravity research lacks a Kuhnian \"crisis\" or \"revolution,\" as core principles remain unchallenged despite anomalies. Thus, while Kuhn's framework is invoked, its applicability to quantum gravity is contested, with no clear paradigm shift yet occurring.  \n",
      "\n",
      "(Word count: 100)\n",
      "Sources:\n",
      "  Source 1: Audretsch. QG&StrucOfSciRevo.pdf - Page 9\n",
      "  Source 2: Crane-ExploratoryStudyKuhnian-1980.pdf - Page 11\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "import glob\n",
    "\n",
    "#### Your Task ####\n",
    "# This is a major task that requires some thinking and time. \n",
    "# Build a conversation system from a collection of research papers of your choice. \n",
    "# You can ask specific questions of a method about these papers, and the agent returns a brief answer to you (with no more than 100 words). \n",
    "# Save your data and ChromaDB in the /ssdshare/llm-course/<YOUR-NAME> directory so other people can use it. \n",
    "# Provide at least three query examples so the TAs can review your work. \n",
    "# You may use any tool from the past four labs or from the langchain docs, or any open source project. \n",
    "# write a summary (a Markdown cell) at the end of the notebook summarizing what works and what does not. \n",
    "\n",
    "# Load the research papers and create a conversational system\n",
    "\n",
    "# 1. First, load the PDF files from the specified directory\n",
    "\n",
    "# Directory to save our database\n",
    "output_dir = \"/ssdshare/llm-course/gzh/papers_db\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load PDF files\n",
    "papers_dir = \"/ssdshare/llm-course/gzh\"  # Changed to absolute path\n",
    "pdf_files = glob.glob(os.path.join(papers_dir, \"*.pdf\"))\n",
    "\n",
    "all_docs = []\n",
    "for pdf_file in pdf_files:\n",
    "    loader = PyPDFLoader(pdf_file)\n",
    "    documents = loader.load()\n",
    "    for doc in documents:\n",
    "        # Add source filename to metadata\n",
    "        doc.metadata[\"source\"] = os.path.basename(pdf_file)\n",
    "    all_docs.extend(documents)\n",
    "\n",
    "# 2. Split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "chunks = text_splitter.split_documents(all_docs)\n",
    "\n",
    "# 3. Create embeddings and store in ChromaDB\n",
    "baai_embedding = OpenAIEmbeddings(\n",
    "    model=\"BAAI/bge-m3\",\n",
    "    base_url=os.environ.get(\"SF_BASE_URL\"),\n",
    "    api_key=os.environ.get(\"SF_API_KEY\"),\n",
    ")\n",
    "\n",
    "papers_db = Chroma(\n",
    "    embedding_function=baai_embedding,\n",
    "    persist_directory=output_dir,\n",
    "    collection_name=\"quantum_gravity_papers\"\n",
    ")\n",
    "papers_db.reset_collection()\n",
    "\n",
    "# Embed and store chunks in batches to avoid memory issues\n",
    "batch_size = 50\n",
    "for i in range(0, len(chunks), batch_size):\n",
    "    batch_end = min(i + batch_size, len(chunks))\n",
    "    print(f\"Adding chunks {i} to {batch_end-1}\")\n",
    "    papers_db.add_documents(chunks[i:batch_end])\n",
    "# 4. Build a conversational retrieval chain with memory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    output_key=\"answer\",  # Add this line to specify which output to save\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model=CHAT_MODEL)\n",
    "\n",
    "# Custom prompt to ensure brief answers\n",
    "qa_prompt_template = \"\"\"You are a helpful AI assistant that answers questions about research papers on quantum gravity and philosophy of science.\n",
    "Use the following pieces of context to answer the question at the end. \n",
    "If you don't know the answer, just say you don't know. Don't make up an answer.\n",
    "Keep your answer brief and concise - no more than 100 words.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Your answer (maximum 100 words):\"\"\"\n",
    "qa_prompt = PromptTemplate.from_template(qa_prompt_template)\n",
    "\n",
    "# Create a retrieval chain\n",
    "retriever = papers_db.as_retriever(search_kwargs={\"k\": 6})\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={\"prompt\": qa_prompt},\n",
    "    verbose=True,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Demo function to show conversation capability\n",
    "def chat_with_papers(questions):\n",
    "    for i, query in enumerate(questions):\n",
    "        print(f\"\\nQuestion {i+1}: {query}\")\n",
    "        result = qa_chain({\"question\": query})\n",
    "        print(f\"Answer: {result['answer']}\")\n",
    "        print(\"Sources:\")\n",
    "        for j, doc in enumerate(result['source_documents'][:2]):\n",
    "            print(f\"  Source {j+1}: {doc.metadata.get('source', 'Unknown')} - Page {doc.metadata.get('page', 'Unknown')}\")\n",
    "\n",
    "# Example queries to demonstrate system capabilities\n",
    "example_conversation = [\n",
    "    \"What is quantum gravity and why is it important?\",\n",
    "    \"How did Einstein contribute to this field?\",\n",
    "    \"What philosophical challenges does quantum gravity present?\",\n",
    "    \"How does Kuhn's theory of scientific revolutions relate to quantum gravity research?\"\n",
    "]\n",
    "\n",
    "print(\"\\nDemonstrating conversational capability:\")\n",
    "chat_with_papers(example_conversation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe371bf",
   "metadata": {},
   "source": [
    "### Summary of Quantum Gravity Research Papers Conversational System\n",
    "\n",
    "#### What Works\n",
    "- Successfully loaded and processed PDF research papers on quantum gravity and philosophy of science\n",
    "- Effective document chunking using RecursiveCharacterTextSplitter (500-character chunks with 100-character overlap)\n",
    "- Vector embeddings created with BAAI/bge-m3 model and stored in ChromaDB\n",
    "- Implemented conversation memory to maintain context across questions\n",
    "- Custom prompt template ensures concise answers (100 words maximum)\n",
    "- Retrieval system fetches relevant context (k=6) to support accurate responses\n",
    "- Returns source documents for answer verification and attribution\n",
    "\n",
    "#### What Could Be Improved\n",
    "- Limited corpus size may restrict the breadth of answerable questions\n",
    "- No filtering mechanism to prioritize more authoritative or recent papers\n",
    "- Batch processing of embeddings could be optimized for larger document collections\n",
    "- No semantic search fallback when exact matches aren't found\n",
    "- Could implement more sophisticated retrieval techniques (map-reduce) for complex questions\n",
    "- No evaluation metrics to assess answer quality and relevance systematically\n",
    "\n",
    "The system demonstrates effective RAG capabilities for specialized academic content but would benefit from expanded corpus size and advanced retrieval methods for complex theoretical questions about quantum gravity and philosophy of science.\n",
    "\n",
    "The code and the report is generated by copilot (Claude 3.7 Sonnet Thinking), using prompt **\"finish the task using papers in /ssdshare/llm_course/gzh: 'Ashtekar. WindingRoadToQG.pdf' ...(other papers omitted)\"** and **\"write a summary of the task\"**. I modified the code a little bit to fix the problem of oversized batch (~800 compared to limit of 64)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
